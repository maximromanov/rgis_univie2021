[
["index.html", "070184 UE Methodological course - Digital Humanities Skills: Intro to GIS (2021S), R Edition Preliminaries", " 070184 UE Methodological course - Digital Humanities Skills: Intro to GIS (2021S), R Edition Maxim G. Romanov 2021-05-31 Preliminaries This is a collection of relevant materials for a DH course by the Department of History, the University of Vienna. Course: 070184 UE Methodological course - Digital Humanities Skills: Intro to GIS (2021S), R Edition u:find Link: https://ufind.univie.ac.at/en/course.html?lv=070184&amp;semester=2021S Meeting time: Tu 11:30-13:00 Meeting place: due to COVID, all meetings will be held online Instructor: Dr. Maxim Romanov, maxim.romanov@univie.ac.at Language of instruction: English Office hours: Tu 13:30-15:00 (on Zoom; please, contact beforehand!) Office: Department of History, Maria-Theresien-Straße 9, 1090 Wien, Room 1.10 "],
["l01-intro.html", "1 L01: Intro 1.1 General Introduction: Making Sure Everything Works; Getting to know R 1.2 Goals{G01} 1.3 Software 1.4 Class 1.5 Starting with our first workbook 1.6 Topics covered 1.7 Reference materials 1.8 Homework{HW01} 1.9 Common issues with homework 1.10 Submitting homework{SH01}", " 1 L01: Intro 1.1 General Introduction: Making Sure Everything Works; Getting to know R 1.2 Goals{G01} Install R and R Studio and start working with them R https://www.r-project.org/ R Studio https://www.rstudio.com/ Get to know R Notebooks (R markdown) 1.3 Software R https://www.r-project.org/ R Studio https://www.rstudio.com/ 1.4 Class R Studio Interface Installing libraries (packages) R Notebook elements: combining prose and code Converting R Notebook into different formats 1.4.1 Installing rmarkdown Instructions here: https://bookdown.org/yihui/rmarkdown/installation.html More information on R Markdown: https://rmarkdown.rstudio.com/lesson-1.html https://bookdown.org/yihui/rmarkdown/ 1.5 Starting with our first workbook Now, download a worksheet file (01_worksheets_familiar-with-r.Rmd.zip). Unzip it and open in RStudio. Let’s work through it! NB: Original worksheets prepared by Lincoln Mullen, GMU (https://dh-r.lincolnmullen.com/worksheets.html) 1.6 Topics covered Values Variables Vectors Built-in functions Using the documentation Data frames Installing and loading packages Simple plots 1.7 Reference materials R Primer (https://dh-r.lincolnmullen.com/primer.html) in: Lincoln A. Mullen, Computational Historical Thinking: With Applications in R (2018–): https://dh-r.lincolnmullen.com. Use the this primer as a quick introduction to the R language, or as a reference for the rest of the course. The original worksheets have been developed by Lincoln Mullen (https://dh-r.lincolnmullen.com/worksheets.html). The ones used in this class might have undergone some changes and relevant adaptations. Your R installation may ‘speak’ your main language. It is nice on one hand, but can be quite inconvenient in class, where the main language is English. You may have to do cast some spells to switch R into English. Possible solutions can be found here: https://stackoverflow.com/questions/13575180/how-to-change-language-settings-in-r/ 1.8 Homework{HW01} Complete the worksheet Getting familiar with R. Generate the results into HTML or PDF (PDF is a little bit trickier). Submit your homework as described below. 1.9 Common issues with homework 1.9.1 Tracing errors Errors happen all the time. You will run into errors when you run your code. You will run into error messages when “knitting” your document — as a result, your document will not be generated. To resolve this: It is important to run each chunk of code separately to ensure that they all work. If any of the chunks throw errors, you will not be able to “knit” your documents. When you run into an error, R Markdown panel (usually in the lower left corner of RStudio interface) will tell you in which line the error occurred. You will need to fix it the same way you would in Step 1. 1.9.2 Comments / “Commenting out” You do not want to constantly keep [re]installing libraries. So, if a library is already installed, you can “comment out” that line. For example, the code chunk above should become: #install.packages(&quot;historydata&quot;) #install.packages(&quot;dplyr&quot;) Adding # in front of a line (or a section of a line) turns it into a comment and it will not longer be executed. 1.9.3 Random errors Think about the following two lines of code. Any issues that you can explain? (You might want to run these lines in R to get some clues) `?median` variable1 &lt;- DigitalHumanities 1.10 Submitting homework{SH01} Homework assignment must be submitted by the beginning of the next class; Email your homework to the instructor as attachments. In the subject of your email, please, add the following: 070184-LXX-HW-YourLastName-YourMatriculationNumber, where LXX is the numnber of the lesson for which you submit homework; YourLastName is your last name; and YourMatriculationNumber is your matriculation number. "],
["l02-basics-i.html", "2 L02: Basics I 2.1 Basics of R: Data Structures and Subsetting 2.2 Goals 2.3 Software{#02} 2.4 Class 2.5 Topics: Data Structures &amp; Types 2.6 Reference materials 2.7 Homework 2.8 Submitting homework", " 2 L02: Basics I 2.1 Basics of R: Data Structures and Subsetting 2.2 Goals Getting to know main data structures in R 2.3 Software{#02} R https://www.r-project.org/ R Studio https://www.rstudio.com/ 2.4 Class Practice worksheet: 02_worksheets_data-structures.Rmd.zip NB: Original worksheets prepared by Lincoln Mullen, GMU (https://dh-r.lincolnmullen.com/worksheets.html) 2.5 Topics: Data Structures &amp; Types Data structures Vectors Matrices Data frames Lists Subsetting operations 2.5.1 Additional notes str() compactly dysplays information about an R object typeof() determines the internal type or storage mode of an R object class() tells you the data structure of an R object: list data.frame matrix vector numeric typeof() &gt; double — a double-precision vector (floats; default numberic vector type) typeof() &gt; integer — a vector of integers character typeof() &gt; character — a vector of strings/characters Checking class/type &amp; Conversion create test &lt;- c(1,2,3,4,5) is.___ tests whether a variable of a ___ class. or type: check the typeof() our test vector; then try test.ch &lt;- as.character(test) and check the type again; can you convert it back into its initial type?). is.___ converts into a ___ class. (___ is either: vector, matrix, data.frame, list) Now try the following commands and check the type and class of the new objects: test.matrix &lt;- as.matrix(test) test.df &lt;- as.data.frame(test) test.list &lt;- as.list(test) test.vector &lt;- as.vector(test.df$test) 2.6 Reference materials Read two chapters from: Wickham, Hadley. Advanced R, Second Edition. 2 edition. Boca Raton: Chapman and Hall/CRC, 2019. http://adv-r.had.co.nz/ Data structures Subsetting For the next class, read the following article (in open access, simply follow the link): Broman, Karl W., and Kara H. Woo. 2018. “Data Organization in Spreadsheets.” The American Statistician 72 (1): 2–10. https://doi.org/10.1080/00031305.2017.1375989. Additional readings: Read Introduction to Lincoln A. Mullen, Computational Historical Thinking: With Applications in R (2018–): (http://dh-r.lincolnmullen.com/introduction.html) 2.7 Homework Finish your worksheet and submit your HW as described below. 2.8 Submitting homework Homework assignment must be submitted by the beginning of the next class; Email your homework to the instructor as attachments. In the subject of your email, please, add the following: 070184-LXX-HW-YourLastName-YourMatriculationNumber, where LXX is the numnber of the lesson for which you submit homework; YourLastName is your last name; and YourMatriculationNumber is your matriculation number. "],
["l03-basics-ii.html", "3 L03: Basics II 3.1 Data Manipulation &amp; Exloratory Analysis 3.2 Some comments on the previous lesson homework: 3.3 Goals 3.4 Class 3.5 Topics 3.6 Reference materials 3.7 Homework 3.8 Submitting homework", " 3 L03: Basics II 3.1 Data Manipulation &amp; Exloratory Analysis 3.2 Some comments on the previous lesson homework: 3.2.1 Mess with “attachments” R automatically “attaches” a package when a package is loaded. What this means is that you can simply use a command from that package: like glimpse(your_data_frame), which will give you a glimpse into your dataframe; a potential problem with this approach is that you may load another library that might have the same command — and since the later package will override “attachments,” you may not be aware of (or not pay attention to) the fact that you have lost some old connections. R will warn you about any overriding, but you may miss that. This warning message will look like what you see below. How this can be fixed? An efficient way to avoid this is to use the double-colon operator like this: dplyr::glimpse(your_data_frame) If, out of the sudden, the command that worked before stops working and throws an error at you — this mess with attachments is likely to be the problem. library(dplyr) ## ## Attaching package: &#39;dplyr&#39; ## The following objects are masked from &#39;package:stats&#39;: ## ## filter, lag ## The following objects are masked from &#39;package:base&#39;: ## ## intersect, setdiff, setequal, union for more details: https://colinfay.me/intro-to-r/packages.html 3.2.2 Vector operations adding two vectors multiplying two vectors v1 &lt;- c(1,2,3,4,5,6) v2 &lt;- c(1,10) v3 &lt;- c(100) 3.2.3 NA Value? Why do you think we need such a value? 3.2.4 many Vs \"many\" What is the difference, from the example below? many &lt;- c(1,2,3,4,5,6,7) length(&quot;many&quot;) ## [1] 1 length(many) ## [1] 7 3.3 Goals Getting to know the basics of working with data: manipulating data, basic techniques of exploratory analysis 3.4 Class 03_worksheets_data-manipulation-introduction.Rmd.zip 04_worksheets_data-manipulation-continued.Rmd.zip NB: Original worksheets prepared by Lincoln Mullen, GMU (https://dh-r.lincolnmullen.com/worksheets.html) 3.5 Topics Selecting columns (select()) Filtering rows (filter()) Creating new columns (mutate()) Sorting columns (arrange()) Split-apply-combine (group_by()) Summarizing or aggregating data (summarize()) Data joining with two table verbs (left_join() et al.) Data reshaping (spread() and gather()) 3.6 Reference materials Consult relevant chapters from: Healy, Kieran Data Visualization: A Practical Guide. Princeton University Press, 2018. ISBN: 978-0691181622. http://socviz.co/ Hadley Wickham &amp; Garrett Grolemund, R for Data Science: Import, Tidy, Transform, Visualize, and Model Data. O’Reilly, 2017. ISBN: 978-1491910399. https://r4ds.had.co.nz/ Wickham, Hadley. Advanced R, Second Edition. 2 edition. Boca Raton: Chapman and Hall/CRC, 2019. http://adv-r.had.co.nz/ 3.7 Homework Finish your worksheets and submit as described below. Additional: if you’d like more practice, you can use swirl library: To install: install.packages(\"swirl\") To run: library(swirl) Then: swirl() 3.8 Submitting homework Homework assignment must be submitted by the beginning of the next class; Email your homework to the instructor as attachments. In the subject of your email, please, add the following: 070184-LXX-HW-YourLastName-YourMatriculationNumber, where LXX is the numnber of the lesson for which you submit homework; YourLastName is your last name; and YourMatriculationNumber is your matriculation number. "],
["l04-basics-iii.html", "4 L04: Basics III 4.1 Data Visualization; Functions 4.2 Goals 4.3 Class 4.4 Topics 4.5 Reference materials 4.6 Homework 4.7 Submitting homework", " 4 L04: Basics III 4.1 Data Visualization; Functions 4.2 Goals Getting to know the basics of data visualization; writing simple functions (reusable, packaged code) 4.3 Class 05_worksheets_ggplot2-introduction-MGR-mod.Rmd.zip 06_worksheets_functions.Rmd.zip 4.4 Topics Basics of using ggplot2 Basic geoms in ggplot2 Histogram Lines Bar plots Faceting Labels Create your own plots Writing your own functions Explanation of functions Function calls Function definition 4.5 Reference materials Consult relevant chapters from: Healy, Kieran Data Visualization: A Practical Guide. Princeton University Press, 2018. ISBN: 978-0691181622. http://socviz.co/ Hadley Wickham &amp; Garrett Grolemund, R for Data Science: Import, Tidy, Transform, Visualize, and Model Data. O’Reilly, 2017. ISBN: 978-1491910399. https://r4ds.had.co.nz/ Wickham, Hadley. Advanced R, Second Edition. 2 edition. Boca Raton: Chapman and Hall/CRC, 2019. http://adv-r.had.co.nz/ 4.6 Homework Finish your worksheets and submit as described below. During the break: Additional I: I strongly recommend that you keep practicing R. You can use the swirl library for this: To install: install.packages(\"swirl\") To run: library(swirl) Then: swirl() Additional courses/tutorials for swirl() can be found at https://swirlstats.com/scn/title.html I would recommend the following ones (in this order): R Programming by Team swirl Getting and Cleaning Data by Team swirl Exploratory Data Analysis by Team swirl Advanced R Programming by Roger Peng (try others as well; there are also some courses in German and Spanish) Additional II: I strongly recommend that you start looking for the GIS-related readings that you will be reviewing You should also start looking for or thinking about the dataset for your final project (if you do not have one) 4.7 Submitting homework Homework assignment must be submitted by the beginning of the next class; Email your homework to the instructor as attachments. In the subject of your email, please, add the following: 070184-LXX-HW-YourLastName-YourMatriculationNumber, where LXX is the numnber of the lesson for which you submit homework; YourLastName is your last name; and YourMatriculationNumber is your matriculation number. "],
["l05-data-i.html", "5 L05: Data I 5.1 Collecting, Organizing, Creating 5.2 Goals 5.3 Software &amp; Other Required Materials 5.4 In Class I: Theoretical and Conceptual 5.5 Ways of obtaining data 5.6 Main format 5.7 Basic principles of organizing data: Tidy Data 5.8 In Class II: Practical 5.9 Morris Dataset: the East Vs. the West 5.10 Viennese Districts 5.11 Reference Materials 5.12 Additional 5.13 Additional Readings 5.14 Homework 5.15 Submitting homework", " 5 L05: Data I 5.1 Collecting, Organizing, Creating 5.2 Goals Getting to know the basics of working with data: collecting, creating, organizing. 5.3 Software &amp; Other Required Materials R OCR Engines (https://www.onlineocr.net/); text editor (for example, Sublime Text) Excel, Google Spreadsheets, or any other alternative (Easy CSV Editor is a great option for Mac) 5.4 In Class I: Theoretical and Conceptual 5.5 Ways of obtaining data Reusing already produced data One may require to mold data into a more fitting structure. Creating one’s own dataset Digitizing data from printed and/or hand-written sources 5.5.1 Using OCR In class we will use an online OCR engine, but you might want to consider using OCR directly in R. For this purpose, R uses library tesseract, which required Tesseract software to be installed on your computer. You can find detailed instructions here (Warning: this part may be a little bit annoying, but Tesseract is a useful software to have and to know how to use.) Here is some R code that should get you started on using Tesseract (For more details, check the information page): Preparations: library(tesseract) #LANGUAGEDATA: &lt;https://github.com/tesseract-ocr/langdata&gt; tesseract_download(&quot;eng&quot;) # this needs to be done only once tesseract_download(&quot;deu&quot;) # this needs to be done only once Converting an image into a text: pngPage &lt;- &quot;Sample_Page_With_Tabular_Data_Morris.png&quot; text &lt;- tesseract::ocr(pngPage, engine = tesseract(&quot;eng&quot;)) readr::write_lines(text, str_replace(pngPage, &quot;.png&quot;, &quot;.txt&quot;)) Converting a PDF into a text: library(pdftools) # for processing PDFs pdfPages &lt;- &quot;Morris_2013_Combined.pdf&quot; pngFile &lt;- pdftools::pdf_convert(pdfPages, dpi = 600) text &lt;- tesseract::ocr(pngFile, engine = eng) readr::write_lines(text, str_replace(pdfPages, &quot;.pdf&quot;, &quot;.txt&quot;)) 5.6 Main format Relational databases or Tables/Spreadsheets (tabular data)? Tabular format: tables; spreadsheets; CSV/TSV files. Unique identifiers: tables with different data can be connected via unique identifiers Note: A relational database (rDB) is a collection of interconnected tables. Tables in an rDB are connected with each other via unique identifiers which are usually automatically created by the database itself when new data is added. One can maintain interconnected tables without creating a rDB: Linked Open Data Example: Table of the growth of cities. One table includes information on population over time; Another table includes coordinates of the cities from the dataset. It is more efficient and practical (reducing error rate from typos) to work on these tables separately, and connect them via unique identifiers of cities which are used in both tables. 5.6.1 Note on the CSV/TSV format CSV stands for comma-separated values; TSV — for tab-separated values. Below is an examples of a CSV format. Here, the first line is the header, which provides the names of columns; each line is a row, while columns are separated with , commas. city,growth_from_2000_to_2013,latitude,longitude,population,rank,state New York,4.8%,40.7127837,-74.0059413,8405837,1,New York Los Angeles,4.8%,34.0522342,-118.2436849,3884307,2,California Chicago,-6.1%,41.8781136,-87.6297982,2718782,3,Illinois Houston,11.0%,29.7604267,-95.3698028,2195914,4,Texas Philadelphia,2.6%,39.9525839,-75.1652215,1553165,5,Pennsylvania TSV is a better option than a CSV, since TAB characters (\\t) are very unlikely to appear in values. Neither TSV not CSV are good for preserving new line characters (\\n)—or, in other words, text split into multiple lines/paragraphs. As a workaround, one can convert \\n into some unlikely-to-occur character combination (for example, ;;;), which would be easy to restore into \\n later, if necessary. 5.7 Basic principles of organizing data: Tidy Data 5.7.1 Tidy Data Each variable is in its own column Each observation is in its own row Each value is in its own cell Source: Wickham, Hadley, and Garrett Grolemund. 2017. R for Data Science: Import, Tidy, Transform, Visualize, and Model Data. Sebastopol, CA: O’Reilly UK Ltd. https://r4ds.had.co.nz/; for a Chapter on tidy data, see: https://r4ds.had.co.nz/tidy-data.html. 5.7.2 Clean Data Column names and row names are easy to use and informative. In general, it is a good practice to avoid spaces and special characters. Good example: western_cities Alternative good example: WesternCities Bad example: Western Cities (only the largest) Obvious mistakes in the data have been removed Date format: YYYY-MM-DD is the most reliable format. Any thoughts why? There should be no empty cells: If you have them, it might be that your data is not organized properly. If your data is organized properly, NA must be used as an explicit indication that data point is not available. Each cell must contain only one piece of data. Variable values must be internally consistent Be consistent in coding your values: M and man are different values computationally, but may be the same in the dataset; Keep track of your categories: a document where all codes used in the data set are explained. Preserve original values If you are working with a historical dataset, it might be inconsistent. For example, distances between cities are given in different formats: days of travel, miles, farsaḫs/parasangs, etc.). Instead of replacing original values, it is better to create an additional column, where this information will be homogenized according to some principle. Keeping original data will allow to homogenize data in multiple ways. Clearly differentiate between the original and modified/modelled values. The use of suffixes can be convenient: Distance_Orig vs Distance_Modified. Most of editing operations should be performed in software other than R; any spreadsheet program will work, unless it cannot export into CSV/TSV format. Keep in mind that if you prepare your data in an Excel-like program, rich formatting (like manual highlights, bolds, and italics) is not data and it will be lost, when you export your data into CSV/TSV format. Note: It might be useful, however, to use rule-based highlighting in order, for example, to identify bad values that need to be fixed. Back up your data! http://github.com is a great place for this, plus it allows to work collaboratively as well as to keep track of all changes. Google spreadsheets is a decent alternative for collaborative work, but it lacks version control and detailed tracking of changes. 5.8 In Class II: Practical 5.9 Morris Dataset: the East Vs. the West War-making capacity since 4000 BCE (in social development points). Data source: Morris, Ian. 2013. The Measure of Civilization: How Social Development Decides the Fate of Nations. Princeton: Princeton University Press. 5.9.1 Difficulty: Easy Digitize “War-making capacity since 4000 BCE” from this file Morris_2013_Combined.pdf. Fix the dataset so that it conforms to the principles of tidy data. What should be corrected? Load the data set into R Graph chronological changes in war-making capacities for the East and the West. When the East was in the lead? When the West was in the lead? How can you determine that? (Hint: review logical operators and vector comparison). 5.9.2 Difficulty: More complicated Digitize “Maximum Settlement Sizes” from this file Morris_2013_Combined.pdf. Fix the dataset so that it conforms to the principles of tidy data. What should be corrected? The datasets for the East and the West are separate. What would be your strategies to combine them? Graph chronological changes in war-making capacities for the East and the West. When the East was in the lead? What were the most prominent settlements? When the West was in the lead? What were the most prominent settlements? How can you determine that? (Hint: review logical operators and vector comparison). 5.10 Viennese Districts There is quite a lot of data on Vienna at the Wien Geschichte Wiki Website. Your task will be to collect data on 23 viennese districts: 1) numbers of houses; 2) numbers of inhabitants. This information is available on pages of each district. You can find them at the following links: 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23. To get to the data that we need, you will need to click on the link with the actual name of the district. There you will find a detailled description of the district and one of the sections will contain statistics on houses and the inhabitants of the district. Your task will be as follows: to collect this data into tables (CSV files) that will be organizes according to the principles of tidy data; there are 23 districts and 13 students; each one of you will need to collect data on two districts (treat this not as a torture, but as an exercise); please, pick your districts here (write in your name against two districts that you want to pprepare); as always, you are welcome to work collaboratively (there still must be two districts per person though); you are encouraged to use the strategies that we discussed in class and come up with your own (for example, you can carefully retype the data from graphs; but you can also look for the source of this data; both strategies are perfectly fine). in your homework notebook: load the data that you have collected; print out the tables (they are rather small, so print them in full); generate graphs of growth of houses and inhabitants; email CSV files together with your notebooks. 5.11 Reference Materials Wickham, Hadley. 2014. “Tidy Data.” Journal of Statistical Software 59 (10). https://doi.org/10.18637/jss.v059.i10. (The article in open access) Check these slides: A. Ginolhac, E. Koncina, R. Krause. Principles of Tidy Data: tidyr https://lsru.github.io/tv_course/lecture05_tidyr.html (Also check their other lectures/slides: ) Broman, Karl W., and Kara H. Woo. 2018. “Data Organization in Spreadsheets.” The American Statistician 72 (1): 2–10. https://doi.org/10.1080/00031305.2017.1375989. 5.12 Additional Morris, Ian. 2013. The Measure of Civilization: How Social Development Decides the Fate of Nations. Princeton: Princeton University Press. Note: This book is a methodological companion to: Morris, Ian. 2010. Why the West Rules—for Now: The Patterns of History, and What They Reveal about the Future. New York: Farrar, Straus and Giroux. 5.13 Additional Readings Wickham, Hadley. 2014. “Tidy Data.” Journal of Statistical Software 59 (10). https://doi.org/10.18637/jss.v059.i10. (The article in open access) 5.14 Homework Finish the assignment started in class; email report (ideally, as a PDF, since now it will include graphs). Find your own small data set published in a book or an article; digitize it using strategies discussed in class; run some analytical tasks (anything from what you have learned so far); create a report. Email both reports. 5.15 Submitting homework Homework assignment must be submitted by the beginning of the next class; Email your homework to the instructor as attachments. In the subject of your email, please, add the following: 070184-LXX-HW-YourLastName-YourMatriculationNumber, where LXX is the numnber of the lesson for which you submit homework; YourLastName is your last name; and YourMatriculationNumber is your matriculation number. "],
["l06-data-ii.html", "6 L06: Data II 6.1 Modeling &amp; Manipulating 6.2 Goals 6.3 Software 6.4 Additional Materials 6.5 In Class I: Theoretical and Conceptual 6.6 Ways of modeling data: Categorization 6.7 Normalization 6.8 Note: Proxies, Features, Abstractions 6.9 In Class II: Practical 6.10 Bosker et al. Dataset 6.11 Reference Materials 6.12 Additional Readings 6.13 Homework 6.14 Submitting homework", " 6 L06: Data II 6.1 Modeling &amp; Manipulating 6.2 Goals Getting to know the basics of working with data: modeling, manipulating 6.3 Software R Excel, Google Spreadsheets, or any other alternative 6.4 Additional Materials Two excellent books on data visualization with R (both available onlenly online): Kieran Healy. Data Visualization: A Practical Guide, https://socviz.co/. This book is more conceptual and is more of a textbook Everybody should read the first chapter “Look at Data!” (https://socviz.co/lookatdata.html) Rob Kabacoff. Data Visualization with R, https://rkabacoff.github.io/datavis/ This book is more of a reference and a cookbook 6.5 In Class I: Theoretical and Conceptual 6.6 Ways of modeling data: Categorization “[Modeling is] a continual process of coming to know by manipulating representations.” Willard McCarty, “Modeling: A Study in Words and Meanings,” in Susan Schreibman, Ray Siemens, and John Unsworth, A New Companion to Digital Humanities, 2nd ed. (Chichester, UK, 2016), http://www.digitalhumanities.org/companion/. One of the most common way of modeling data in historical research—joining items into broader categories. Categorization is important because it allows to group items with low frequencies into items with higher frequencies, and through those discern patterns and trends. Additionally, alternative categorizations allow one to test different perspectives on historical data. The overall process is rather simple in terms of technological implementation, but is quite complex in terms of subject knowledge and specialized expertise is required to make well-informed decisions. For example, let’s say we have the following categories: baker, blacksmith, coppersmith, confectioner, and goldsmith. These can be categorized as occupations; Additionally, blacksmith, coppersmith, and goldsmith can also be categorized as ‘metal industry’, while baker and confectioner, can be categorized as ‘food industry’; Yet even more, one might want to introduce additional categories, such as luxury production to include items like goldsmith and confectioner; and regular production for items like baker, blacksmith, coppersmith. Such categorizations can be created in two different ways, with each having its advantages: first, one can create them as additional columns. This approach will allow to always have the original—or alternative—classifications at hand, which is helpful for re-thinking classifications and creating alternative ones where items will be reclassified differently, based on a different set of assumptions about your subject. second, these can be created in separate files, which might be easier as one does not have to stare at existing classifications and therefore will be less influenced by them in making new classification decisions. Additionally, one can use some pre-existing classifications that have already been created in academic literature. These most likely need to be digitized and converted into properly formatted data, as we discussed in the previous lesson. 6.7 Normalization This is a rather simple, yet important procedure, which is, on the technical side, very similar to what was described above. In essence, the main goal of normalization is to remove insignificant differences that may hinder analysis. Most common examples would be: bringing information to the same format (e.g., dates, names, etc.) unifying spelling differences The best practice is to preserve the initial data, creating normalized data in separate columns (or tables) 6.8 Note: Proxies, Features, Abstractions These are the terms that refer to the same idea. The notion of proxies is used in data visualization, that of features—in computer science; that of abstractions—in the humanities. The main idea behind these terms is that some simple features of an object can act as proxies to some complex phenomena. For example, Ian Morris uses the size of cities as a proxy to the complexity of social organization. The logic is following: the larger the size of a city, the more complex social, economic and technical organization is required to keep that city functional, therefore is can be used as an indicator of the social complexity. While proxies are selected from what is available—usually not much, especially when it comes to historical data—as a way to approach something more complex, it may be argued that abstractions are often arrived to from the opposite direction. We start with an object which is available in its complexity and we reduce its complexity to a more manageable form which—we expect—would prepresent a particular aspect of the initial complex object. Most commonly this is applied to texts in a natural language. For example, in stylometry texts are reduced to freqiency lists of most frequent features, which are expected to represent an authorial fingerprint. The complexity of texts can be reduced in a number of ways: into a list of lemmas (e.g., for topic modeling analysis), frequency lists (e.g., for document distance comparison), syntactic structures, ngrams, etc. This list is never set and researchers can create multiple abstractions depending on their research questions. 6.9 In Class II: Practical Data for the practical session and homework: Bosker_Data.zip. The data is available in open access and is a supplement to a study (see, Reference Materials). The zipped file includes everything you need for the practical session. Download and unzip (read the article at home!). Note: create a notebook and work through the following questions. Group work is encouraged. Please, explain in one or two sentences what you do in each step, so that your work is also human-readable. Please, submit this notebook as your homework. Make sure to name your file in the following manner: 070184-LXX-HW-YourLastName-YourMatriculationNumber.EXT, where LXX is the number of the lesson for which you submit homework; YourLastName is your last name; and YourMatriculationNumber is your matriculation number; EXT is the extension of your file — yopu can submit it either as HTML or as a PDF. 6.10 Bosker et al. Dataset Please, provide your answers (a few sentences) and/or working code to the following questions: Describe and provide working R code: Can you figure which file contains data? In which format is data? How can we load it into R? Describe and provide working R code: What is the chronological extent of this data? Describe: [easy-ish] What periods can it be divided into? How can we do that? Describe, provide more than one strategy. (Comment: Sometimes you must be precise, sometimes approximation may be sufficient; also, consider such issues as reliability and availability of data. Is the data that you have reliable? Are necessary values available? Etc.) How can we introduce the following categories into this data: [easy] North Africa and Europe? [a bit more complicated] the Austro-Hungarian Empire? Optional coding When did the Empire had the largest number of cities (based on the data set)? Optional coding When was its population at the highest? [a tad tricky] Christiandom and Islamdom? Optional coding What are the largest cities of Islamdom for each reported period? Optional coding What are the largest western cities of Islamdom between 1000 and 1500 CE? 6.11 Reference Materials Bosker, Maarten, Eltjo Buringh, and Jan Luiten van Zanden. 2012. “From Baghdad to London: Unraveling Urban Development in Europe, the Middle East, and North Africa, 800–1800.” The Review of Economics and Statistics 95 (4): 1418–37. https://doi.org/10.1162/REST_a_00284. Bosker, Maarten, Eltjo Buringh, and Jan Luiten Van Zanden. 2014. “Replication Data for: From Baghdad to London: Unraveling Urban Development in Europe, the Middle East, and North Africa, 800-1800.” Harvard Dataverse. https://doi.org/10.7910/DVN/24747. 6.12 Additional Readings Moretti, Franco. 2007. Graphs, Maps, Trees: Abstract Models for Literary History. London - New York: Verso. Moretti, Franco. 2013. Distant Reading. London ; New York: Verso. Romanov, Maxim G. 2017. “Algorithmic Analysis of Medieval Arabic Biographical Collections.” Speculum 92 (S1): S226–46. https://doi.org/10.1086/693970. 6.13 Homework Bosker et al. Dataset. Finish the practical assignment on the Bosker et al. Dataset. Viennese Dataset Assignments. Collectively, you should now have all the data on Vienna’s districts. Next assignment is as follows: Work together to create one dataset with all the data on houses and inhabitants on Vienna; what would be the best structure for this dataset? Make graphs of the growth of all districts — both, for houses and for inhabitants Make a graph of the growth of Vienna using this data. Here, again, you should have two graphs (two perspectives): one based on the number of houses, and another — on the number of inhabitants. After you have the graph, provide your interpretation (this implies looking for additional information, not simply relying on the graph). Data visualizations: Please, make sure to read Kieran Healy’s “Look at Data!” (https://socviz.co/lookatdata.html) Using what you have learned in the chapter, take a close look at the following datasets (given in the order of increasing size and complexity) and think about how they can be visualized. The main goal is to come up with verbal descriptions of how this data can be visualized and what you may expect to learn from these visualizations. You are, of course, welcome to generate those visualizations. Again, group work is encouraged — brainstorming is particularly good for this task. historydata::early_colleges europop::europop historydata::us_cities_pop Note: you can put everything in one notebook. Do not forget to send me your work! 6.14 Submitting homework Homework assignment must be submitted by the beginning of the next class; Email your homework to the instructor as attachments. In the subject of your email, please, add the following: 070184-LXX-HW-YourLastName-YourMatriculationNumber, where LXX is the numnber of the lesson for which you submit homework; YourLastName is your last name; and YourMatriculationNumber is your matriculation number. "],
["l07-gis-i.html", "7 L07: GIS I 7.1 Georeferencing &amp; Geocoding 7.2 Georeferencing 7.3 Georeferencing maps without a grid 7.4 Geocoding 7.5 Reverse Geocoding 7.6 Homework 7.7 Submitting homework", " 7 L07: GIS I 7.1 Georeferencing &amp; Geocoding 7.1.1 Goals Learning about what georeferencing and geocoding are. Learning how to do georeferencing and geocoding. 7.1.2 Software QGIS, https://qgis.org/ R 7.1.3 Additional Materials QGIS tutorials in Mapping for Historians: http://transnationalhistory.net/mapping/tutorials/ specifically on georeferencing: http://transnationalhistory.net/mapping/tutorials/georeferencing/ More general QGIS Tutorials: http://www.qgistutorials.com/en/index.html Additionally, see tutorials on Programming Historian in the section mapping: https://programminghistorian.org/en/lessons/?topic=mapping Clifford, Jim, Josh MacFadyen, and Daniel Macfarlane. 2013. “Installing QGIS 2.0 and Adding Layers.” Programming Historian, December. https://programminghistorian.org/lessons/qgis-layers. Clifford, Jim, Josh MacFadyen, and Daniel Macfarlane. 2013. “Georeferencing in QGIS 2.0.” Programming Historian, December. https://programminghistorian.org/lessons/georeferencing-qgis. 7.2 Georeferencing Georeferencing can be defined as a process of associating digital images (pictures of a maps) with locations in physical space. What we do in this process is projecting an image of a map on geographical coordinate system. After this process of projection or association is complete, objects on georeferenced maps acquire geographical coordinates, which can be harvested for use in other projects. 7.2.1 QGIS QGIS must be installed and running. Note: Interfaces might differ from system to system; the same applies to different versions of QGIS. Before we proceed, you may want to add Google Layers. To Add Google maps layer: (on the left pane, Browser) XYZ &gt; New connection &gt; paste one of the following links (Source: https://geogeek.xyz/how-to-add-google-maps-layers-in-qgis-3.html): Google Maps: https://mt1.google.com/vt/lyrs=r&amp;x={x}&amp;y={y}&amp;z={z} Google Satellite: http://www.google.cn/maps/vt?lyrs=s@189&amp;gl=cn&amp;x={x}&amp;y={y}&amp;z={z} Google Satellite Hybrid: https://mt1.google.com/vt/lyrs=y&amp;x={x}&amp;y={y}&amp;z={z} Google Terrain: https://mt1.google.com/vt/lyrs=t&amp;x={x}&amp;y={y}&amp;z={z} Google Roads: https://mt1.google.com/vt/lyrs=h&amp;x={x}&amp;y={y}&amp;z={z} NB: Images of maps to work with below 7.2.2 Step-by-step instructions Let’s georeference this old map of Europe. Here is the link: OldDesignShop_MapCentralEurope.jpg. In your XYZ Tiles, double click on any Google layer that you added (or on OpenStreetMap) A layer should be added to the main map (see, Layer pane) Open Georeferencer: Raster &gt; Georeferencer if you do not see it there, it must be activated first: Plugins &gt; Manage and Install Plugins... &gt; [search for georeferencer], then tick a box against Georeferencer GDAL In Georeferencer: File &gt; Open Raster (also the first button on the main panel) Choose a file. Lets start with OldDesignShop_MapCentralEurope.jpg (this one has a grid, so it will be easier to process) In Coordinate Reference System Selector, choose WGS 84 / Pseudo-Mercator, then clock OK Open Settings &gt; Transformation settings (or click the yellow gears button) Choose settings like on the screenshot below (you can also change Compression setting, which will generate a smaller map-image): Important! Make sure to select EPSG:4326 - WGS 84 in Target SRS. (If your map is tiny and appears somewhere in the Atlantic ocean near the coast of West Africa, you have selected a wrong target Spatial Reference System!) Now, adding georeference points: If you have a grid, it is very easy: just type in coordinates If you don’t, it is tricky: you need to find the same features on the image and on the map (for this, click on From Map Canvas) [!!!] Ideally, if you know projection of the map, you only need a few points; this almost never happens, so, the more points you create, the more precisely your image will be georeferenced. This is easy when you have a grid. When you are done with collecting points, click on PLAY button (green triangle) The image of your georeferenced map should appear in the main window. [!!!] Keep in mind that you add layers to your map and a layer on top may cover the layer below! Below you can see how a georeferences map would look, if only 4 points GCP (ground reference points) have been collected. In the areas circled with red you can see that the northern par of the UK and Denmark are not very well aligned. In the example below you the georeferences map has about a dozen GCP. Alignment of the northern part of the UK and Denmark is much better. In general, if you have a clear coordinate grid on your maps, you may want to georeference all intersections—this will give you the best possible results. In general, this procedure can be extremely helpful if: you need to collect geographical information from historical maps; you want to use some historical map as the base layer for mapping your data; 7.3 Georeferencing maps without a grid You may have a map that does not have any grid. In this case you will have to georeference your map by visual cues. The steps are the same as above, but instead of typing in the coordinates, you will need to identify the same visual features on the map that you georeference (your source map) and the base layer map loaded into QGIS (your target map). First, you click on the selected feature on your source map. Then, click on “From Map Canvas” Then, find the same feature on the target map and click there — the GCP will be automatically created. For for our practice we will use the following old map of Vienna (Source: David Ramsey Map Collection) In my attempt, I just picked three points in the 1st district: Burgtor, Schottentor, and Domkirche St. Stephan. The results are not too bad, but if you look closer areas outside of the 1st district are not well aligned. In cases you need data from such a map, you will need to collect as many points as possible. For better transformation results, these points also should be distributed evenly across the surface of your source map and at the same time evenly distanced from each other — like a grid. 7.3.1 Collecting Point Data (Very Simple Way) Create a CSV file; copy/paste the content from below (six lines of text!) city,state,lon,lat Warsaw,Russia,21.13066,52.23914 Berlin,Germany,13.38309,52.54312 Hamburg,Germany,9.98335,53.54092 Vienna,Austria-Hungary,16.39089,48.27847 Budapest,Austria-Hungary,19.05326,47.50452 In QGIS, load this file by: Layer &gt; Add Layer &gt; Add Delimited Text Layer Settings should look like on the screenshor below CSV (comma separated format) Point coodinates (X field: lon; Y field: lat) Geometry CRS: EPSG:4326 - WGS 84 / Pseudo Mercator (you will have only two lines of data, instead of five) Make sure to click Add when you are done! * The layer is there, but we need to add labels to see the cities * Right-click on the layer &gt; Properties * On the tab Labels change the settings like on the screenshot below * Click Apply, then OK. * You should see several cities on the map now: * If nothing appears, try: Right-click on the layer &gt; Set CRS &gt; Set Layer CRS: Choose WGS 84 / Pseudo-Mercator * Now, we can use Coordinate Capture plugin to collect data from our georeferenced map: * If activated, coordinarte capture should be visible in lower right corner * To activate coordinate capture: Plugins &gt; Manage and Install Plugins... &gt; [search for coordinate capture], then tick a box against Coordinate Capture * You might still need to do: Vector &gt; Coordinate Capture to make it appear. Collecting coordinates: Keep the initial CSV open in some editor; In Coordinate Capture, click Start capture; Click on any point on the map &gt; coordinates of that location will appear in the plugin; Choose the top coordinates (see image above), click on an icon to the right of the coordinates to copy them; Go back to the open CSV: Add a new line: Type the name of the city; Add comma and type the name of the country (alternatively, just add another comma if you want to keep it empty); Now, paste what you copied into Clipboard (this will add a set of coordinates) Save the file Back in QGIS: Newly-added city must appear on the map. (if not, try to switch the layer off and on.) Repeat, until all required data is collected. 7.4 Geocoding Geocoding is a process through which we obtain coordinates of places for which we know only names. The code below takes information that we provide and sends a request to some geocoding service, which—if matches are found—returns results. Geocoding is a simple way to collect coordinates for locations that you have. As you will see in the code below, you will need the name of the place and the name of the country to get matches. Historians, however, should be very careful with this approach, since it works reliably only for the current modern data. (Important: you should always read documnetation for packages that you use in order to understand better what you can and cannot do with it.) We wil need the following libraries: library(tidyverse) library(tidygeocoder) Now we need to build a simple table with some data. tribble function builds a tibble row by row. The first row is column names, then we can add values in lines that follow (splitting into lines is for visual readability). dynasties &lt;- tribble( ~name, ~city, ~country, ~dynasty, &quot;Dimašq&quot;,&quot;Damascus&quot;, &quot;Syria&quot;, &quot;Umayyads&quot;, &quot;Baġdād&quot;, &quot;Baghdad&quot;, &quot;Iraq&quot;, &quot;Abbasids&quot;, &quot;Naysābūr&quot;, &quot;Nishapur&quot;, &quot;Iran&quot;, &quot;Tahirids&quot;, &quot;Qurṭubaŧ&quot;, &quot;Cordoba&quot;, &quot;Spain&quot;, &quot;Spanish Umayyads&quot;, &quot;al-Qāhiraŧ&quot;, &quot;Cairo&quot;, &quot;Egypt&quot;, &quot;Mamluks&quot;, &quot;Buḫārá&quot;, &quot;Bukhara&quot;, &quot;Uzbekistan&quot;, &quot;Samanids&quot;) Now, the following line calls the function geocode (from tidygeocoder) and tries to get all the relevant data from Open Street Maps (osm). You can check the page of the library for more detials: https://jessecambon.github.io/2020/07/15/tidygeocoder-1-0-0.html. dynasties_locations &lt;- dynasties %&gt;% tidygeocoder::geocode(city = city, country = country, method = &#39;osm&#39;, full_results = TRUE, custom_query= list(extratags = 1)) dynasties_locations ## # A tibble: 6 x 40 ## name city country dynasty lat long place_id licence osm_type osm_id ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; ## 1 Dima… Dama… Syria Umayya… 33.5 36.3 1.08e7 Data ©… node 1.09e9 ## 2 Baġd… Bagh… Iraq Abbasi… 33.3 44.4 2.60e8 Data ©… relation 5.64e6 ## 3 Nays… Nish… Iran Tahiri… 36.2 58.8 2.59e8 Data ©… relation 9.52e6 ## 4 Qurṭ… Cord… Spain Spanis… 37.9 -4.78 2.59e8 Data ©… relation 3.43e5 ## 5 al-Q… Cairo Egypt Mamluks 30.0 31.2 2.59e8 Data ©… relation 5.47e6 ## 6 Buḫā… Bukh… Uzbeki… Samani… 39.8 64.4 1.02e8 Data ©… way 4.56e7 ## # … with 30 more variables: boundingbox &lt;list&gt;, display_name &lt;chr&gt;, ## # class &lt;chr&gt;, type &lt;chr&gt;, importance &lt;dbl&gt;, icon &lt;chr&gt;, ## # extratags.is_in &lt;chr&gt;, extratags.capital &lt;chr&gt;, extratags.wikidata &lt;chr&gt;, ## # extratags.wikipedia &lt;chr&gt;, extratags.is_capital &lt;chr&gt;, ## # extratags.population &lt;chr&gt;, extratags.place &lt;chr&gt;, ## # extratags.linked_place &lt;chr&gt;, `extratags.capital_ISO3166-1` &lt;chr&gt;, ## # extratags.website &lt;chr&gt;, extratags.ele &lt;chr&gt;, `extratags.ref:ine` &lt;chr&gt;, ## # `extratags.ref:whc` &lt;chr&gt;, extratags.heritage &lt;chr&gt;, ## # `extratags.idee:name` &lt;chr&gt;, `extratags.whc:criteria` &lt;chr&gt;, ## # `extratags.ine:municipio` &lt;chr&gt;, `extratags.population:date` &lt;chr&gt;, ## # `extratags.heritage:operator` &lt;chr&gt;, ## # `extratags.whc:inscription_date` &lt;chr&gt;, extratags.rank &lt;chr&gt;, ## # extratags.border_type &lt;chr&gt;, `extratags.left:province` &lt;chr&gt;, ## # `extratags.right:province` &lt;chr&gt; dynasties_locations_filtered &lt;- dynasties_locations %&gt;% select(name, city, country, lat, long) knitr::kable(dynasties_locations_filtered) name city country lat long Dimašq Damascus Syria 33.51307 36.309581 Baġdād Baghdad Iraq 33.30243 44.378799 Naysābūr Nishapur Iran 36.21059 58.792280 Qurṭubaŧ Cordoba Spain 37.88458 -4.776014 al-Qāhiraŧ Cairo Egypt 30.04439 31.235726 Buḫārá Bukhara Uzbekistan 39.76755 64.423133 To check whether results are any go, we can use the following code to generate a very simple map. (We will get into details of how to build beautiful maps in the next lessons.) library(ggplot2) require(maps) library(ggrepel) Here is a sample code to build a very simple map: ggplot(dynasties_locations, aes(x = long, y = lat)) + borders(&#39;world&#39;) + geom_label_repel(aes(label = name), force = 2, segment.alpha = 0) + geom_point() + theme_void() 7.5 Reverse Geocoding In reverse geocoding we start with coordinates and are trying to get more data on what is there at these cordinates. There is a library revgeo (https://github.com/mhudecheck/revgeo) that we can use for this purpose. This procedure may be convenient to check whether certain coordinates are within the borders of a specific country or not; this, however, again works only for the current, and not for historical data. NB: there is a little glitch with the library, as it sends requests to an URL that is no longer in use. This can be fixed by using this script. Dowload it, unzip it and add it to your code with the following line: pathToRevGeo &lt;- &quot;path/to/the/script/on/your/computer/revgeo.R&quot; source(pathToRevGeo) Now, we can try to get information about a place: revgeo(longitude=16.3637029, latitude=48.2155248, provider = &#39;photon&#39;, output=&#39;frame&#39;) [1] &quot;Getting geocode data from Photon: https://photon.komoot.io/reverse?lon=16.3637029&amp;lat=48.2155248&quot; housenumber street city state zip country 1 11 Maria-Theresien-Straße Wien State Not Found 1090 Österreich 7.6 Homework Finish georeferencing maps: map of Europe (easy); map of Vienna (intermeddiate-hard); add these screenshots of your georeferenced maps to your homework notebook; Collect data on major cities in Austro-Hungary and add them to the map in QGIS; send me a screenshot of completed map; print out the table in the notebook; include the screenshot in the notebook; Geocode 10-15 cities that you have visited in your life; print out the table with those places; generate a simple map with them (use the map as a means to check whether georeferencing worked correctly); Submit your notebook. 7.7 Submitting homework Homework assignment must be submitted by the beginning of the next class; Email your homework to the instructor as attachments. In the subject of your email, please, add the following: 070184-LXX-HW-YourLastName-YourMatriculationNumber, where LXX is the numnber of the lesson for which you submit homework; YourLastName is your last name; and YourMatriculationNumber is your matriculation number. "],
["l08-gis-ii.html", "8 L08: GIS II 8.1 Creating Base Maps 8.2 Core concepts and their practical implementations 8.3 Base maps 8.4 Other base maps: ggmap 8.5 Artistic Maps 8.6 Homework 8.7 Additional Materials 8.8 Submitting homework", " 8 L08: GIS II 8.1 Creating Base Maps A base map is the foundational layer of your map with necessary contextual information. It provides coontext for additional layers—those with analytical information—that are added on top of the base map. Most commonly, base maps provide location references for features that do not change often like shorelines, boundaries, rivers, lakes, roads. 8.1.1 Goals To practice building base maps. 8.1.2 Software R 8.2 Core concepts and their practical implementations 8.2.1 Projection Issues See, https://en.wikipedia.org/wiki/List_of_map_projections. Website https://thetruesize.com/ is a nice tool for demonstrating how projection affects our perceprion of reality. On te following two screenshots you can see how the “sizes” of Russia (~17,1 mln km2) and China (c. 9,6 mln. km2) change when they change places. 8.2.2 A Digital Map: Layers of Goodness Layers: Analytical Layer Our Data Annotation/Legend Social Geography Political Boundaries Settlements, etc. Physical Geography Types of surface (raster) Continents / Coastal Line Elevation profile (raster) Rivers, Lakes, etc. Base Layer: Graticule 8.2.3 Main Types of Data: Points, Lines, Polygons SOURCE: There are 3 types of vector objects: points, lines or polygons. Each object type has a different structure. Image Source: Colin Williams (NEON), via: www.earthdatascience.org Analytical Layers: Our Data Points: item1, x[1], point(lat, lon)[2]; item2, x[1], point(lat, lon)[2]; item3, x[1], point(lat, lon)[2]; … itemX, x[1], point(lat, lon)[2]; Lines: line1, x[1], {from(lat, lon)[2], to(lat, lon); from(lat, lon)[2], to(lat, lon); from(lat, lon)[2], to(lat, lon); … from(lat, lon)[2], to(lat, lon);}[2] … lineX … Polygons: polygon1, x, area(lat1, lon1; lat2, lon2; … latX, lonX; … lat1, lon1)[2] … polygonX … Annotation/Legend [1] where x is a categorical parameter; [2] lat/lon: decimal coordinates (not DMS) 8.3 Base maps Base map is essentially the foundation map on which you will be adding data that you want to analyze. It is good to have the base map put together and ready for reuse. 8.3.1 Getting some libraries install.packages(c(&quot;ggplot2&quot;, &quot;ggrepel&quot;, &quot;ggspatial&quot;, &quot;libwgeom&quot;, &quot;sf&quot;, &quot;rnaturalearth&quot;, &quot;rnaturalearthdata&quot;, &quot;rgdal&quot;)) 8.3.2 Creating the Base Map library(tidyverse) library(sf) ## Linking to GEOS 3.8.1, GDAL 3.1.4, PROJ 6.3.1 Let’s load the first base layer of geographical data: library(rnaturalearth) library(rnaturalearthdata) world &lt;- ne_countries(scale = &quot;medium&quot;, returnclass = &quot;sf&quot;) So, here is our base map. Something is missing… theme_set(theme_bw()) xlim=c(-12,80); ylim=c(10,50) ggplot(data = world) + geom_sf(fill=&quot;white&quot;, color=&quot;white&quot;) + coord_sf(xlim = xlim, ylim = ylim, expand = FALSE) + theme(panel.background = element_rect(fill = &quot;grey90&quot;)) Let’s try to add rivers… and the Aral Sea, which almost completely disappeared in the past 40 years of so. For this, we will need to get relevant data files—most likely in shape format used in GIS applications like ArcGIS and QGIS. Googling usually works for finding relevant data. Files for the Aral Sea: http://www.marineregions.org/gazetteer.php?p=details&amp;id=4281. Working with shape files is a bit tricky and we need some extra steps to convert shape files into something that R understands, namely, dataframes. library(rgdal) # R wrapper around GDAL/OGR library(ggmap) # for fortifying shapefiles (converting GIS files into data frames) NB: ggmap is a versetile library that brings additional geospatial capabilities to ggplot, but also has a number of its own functions useful for geospatial analysis. For example, its function fortify() converts GIS data (*.shp files) into data frames with which R works. Additionally, it allows you to pull base maps from such providers as Google, Stamen, and Open Street Maps (for more details, see: https://github.com/dkahle/ggmap). Now, let’s read in the shapefile, using the path to the shapefile and the shapefile name minus the extension as arguments. Keep in mind, that the first argument—the path—should not have the trailing /. (See, readOGR) First, download the following two files and unzip them (change paths to files if necessary!): layer.riverData.zip layer.aral_sea.zip # Rivers rivers &lt;- readOGR(&quot;./data_temp/layer.riverData&quot;, &quot;ne_50m_rivers_lake_centerlines&quot;) ## OGR data source with driver: ESRI Shapefile ## Source: &quot;/Users/romanovienna/Dropbox/6_Teaching_New/_rgis_course/rgis_univie2021_draft/data_temp/layer.riverData&quot;, layer: &quot;ne_50m_rivers_lake_centerlines&quot; ## with 462 features ## It has 32 fields ## Integer64 fields read as strings: ne_id rivers_df &lt;- fortify(rivers) # adding the Aral sea -- historical basin aral_sea &lt;- readOGR(&quot;./data_temp/layer.aral_sea&quot;, &quot;worldglwd1&quot;) ## OGR data source with driver: ESRI Shapefile ## Source: &quot;/Users/romanovienna/Dropbox/6_Teaching_New/_rgis_course/rgis_univie2021_draft/data_temp/layer.aral_sea&quot;, layer: &quot;worldglwd1&quot; ## with 1 features ## It has 28 fields aral_sea_df &lt;- fortify(aral_sea) Let’s try to save these as rData objects (*.rds) and load them, instead of preprocessing shape files everytime, which may take a while. Loading RDS files is just a jiffy. Keep in mind, that you can save any data into RDS file! This might be particularly valuable for storing intermediate results that you do not want to regenerate too often. RDSfolder = &quot;./data_temp/map.objects/&quot; saveRDS(rivers_df, paste0(RDSfolder,&quot;rivers_df.rds&quot;)) saveRDS(aral_sea_df, paste0(RDSfolder,&quot;aral_sea_df.rds&quot;)) rivers_df &lt;- readRDS(paste0(RDSfolder,&quot;rivers_df.rds&quot;)) aral_sea_df &lt;- readRDS(paste0(RDSfolder,&quot;aral_sea_df.rds&quot;)) You can now comment out code in shape_data chunk and saveRDS() lines in RDS_files chunk. The entire script will work much faster this way. waterColor = &quot;lightsteelblue2&quot; # &quot;grey90&quot; xlim=c(-12,80); ylim=c(10,50) ggplot(data = world) + geom_sf(fill=&quot;white&quot;, color=&quot;white&quot;) + # rivers and the aral sea geom_path(data = rivers_df,aes(x = long, y = lat, group = group), color = waterColor, size = .2) + geom_polygon(data = aral_sea_df,aes(x = long, y = lat, group = group), color = waterColor, fill = waterColor, size = .2) + # map limits and theme coord_sf(xlim = xlim, ylim = ylim, expand = FALSE) + theme(panel.background = element_rect(fill = waterColor)) Let’s add a scale bar. This we can do with the library ggspatial (location parameters are as follows: tl, tr, bl and br — for top left, top right, bottom left, and bottom right). library(&quot;ggspatial&quot;) ## Warning: package &#39;ggspatial&#39; was built under R version 4.0.2 xlim=c(-12,80); ylim=c(10,50) ggplot(data = world) + geom_sf(fill=&quot;white&quot;, color=&quot;white&quot;) + # rivers and the aral sea geom_path(data = rivers_df,aes(x = long, y = lat, group = group), color = waterColor, size = .2) + geom_polygon(data = aral_sea_df,aes(x = long, y = lat, group = group), color = waterColor, fill = waterColor, size = .2) + # annotation scale annotation_scale(location = &quot;bl&quot;, width_hint = 0.25) + annotation_north_arrow(location = &quot;bl&quot;, which_north = &quot;true&quot;, pad_x = unit(0.0, &quot;in&quot;), pad_y = unit(0.2, &quot;in&quot;), style = north_arrow_fancy_orienteering) + # map limits and theme coord_sf(xlim = xlim, ylim = ylim, expand = FALSE) + theme(panel.background = element_rect(fill = waterColor), axis.title.y=element_blank(), axis.title.x=element_blank()) For convenience, some of this information can be stored into variables for easy reuse: baseplot &lt;- ggplot(data = world) + geom_sf(fill=&quot;white&quot;, color=&quot;white&quot;) + # rivers and the aral sea geom_path(data = rivers_df,aes(x = long, y = lat, group = group), color = waterColor, size = .2) + geom_polygon(data = aral_sea_df,aes(x = long, y = lat, group = group), color = waterColor, fill = waterColor, size = .2) + # annotation scale annotation_scale(location = &quot;bl&quot;, width_hint = 0.25) + annotation_north_arrow(location = &quot;bl&quot;, which_north = &quot;true&quot;, pad_x = unit(0.0, &quot;in&quot;), pad_y = unit(0.2, &quot;in&quot;), style = north_arrow_fancy_orienteering) + # map limits and theme coord_sf(xlim = xlim, ylim = ylim, expand = FALSE) themeParameters &lt;- theme(panel.background = element_rect(fill = waterColor), axis.title.y=element_blank(), axis.title.x=element_blank(), panel.grid.major = element_line(color = waterColor, linetype = &quot;dotted&quot;, size = 0.5)) Now we can build the same map with just this: baseplot + themeParameters Let’s add some data. You can download this dataset with cities of the world. library(ggrepel) library(readr) worldcities &lt;- read_csv(&quot;files/L11_worldcities.csv&quot;) # xlim=c(-12,80); ylim=c(10,50) wc_filtered &lt;- worldcities %&gt;% filter(between(lat, 10, 50), between(lng, -12, 80)) %&gt;% filter(!is.na(population)) top_cities &lt;- worldcities %&gt;% filter(between(lat, 10, 50), between(lng, -12, 80)) %&gt;% filter(!is.na(population)) %&gt;% top_n(10, wt = population) graph01 &lt;- baseplot + geom_point(data = wc_filtered, aes(x=lng, y=lat, size=population), alpha = 0.5, col=&quot;grey&quot;) + scale_size(range=c(0.01, 2)) + geom_point(data = top_cities, aes(x=lng, y=lat), col=&quot;black&quot;, size=1) + geom_text_repel(data = top_cities, aes(x=lng, y=lat, label = city), force = 2, segment.alpha = 0) + themeParameters graph01 There are plenty ofo things that can be done in orde rto improve the overall look of your maps. One of the things to know an dremember is that yoou can save your map into a separate image file (PNG, TIFF, of JPG — for raster images; SVG or PDF for vector images). The most simple saving command looks like the following: ggsave(&quot;Our_Map.png&quot;, plot=graph01, width = 420, height = 297, units = &quot;mm&quot;, dpi = &quot;retina&quot;) ggsave(&quot;Our_Map.svg&quot;, plot=graph01) By the way, in order to add an image file to your notebook, all you need to use id the following line of code (you add it on a separate line, not enclosing it in '''{r} ... ''' !): ![](path_t_your_file.png) So, this would be our raster map: And this will be our SVG (vector) map: library(grid) # grid library cuts out the plot from the graph gt &lt;- ggplot_gtable(ggplot_build(graph01)) ge &lt;- subset(gt$layout, name == &quot;panel&quot;) ggsave(file=paste0(&quot;graph01.png&quot;), # the following line focuses on the graph plot=grid.draw(gt[ge$t:ge$b, ge$l:ge$r]), # width and height should be experimentally adjusted to remove white space dpi=300,width=8.85,height=4.45) TASK: Create similar maps for at least two other regions (continents or clusters of countries) of your choice. Focus on how your map looks. Experiment with visual improvements; try to add more information and data. 8.4 Other base maps: ggmap ggmap allows us to use maps offered by different providers (for detailed overview, see: https://cfss.uchicago.edu/notes/raster-maps-with-ggmap/). Let’s take a look at a few examples of maps provided by Stamen. (Others are: Google and Open Street Maps) library(osmdata) library(ggmap) place &lt;- &quot;Vienna Austria&quot; bbox &lt;- opq(place)$bbox %&gt;% strsplit(&quot;,&quot;) %&gt;% unlist %&gt;% as.double bb_vienna &lt;- c( left = bbox[2], bottom = bbox[1], right = bbox[4], top = bbox[3] ) vienna_stamen &lt;- get_stamenmap( bbox = c(bb_vienna), zoom = 11 ) ggmap(vienna_stamen) Stamen includes the following types of maps: “terrain,” “terrain-background,” “terrain-labels,” “terrain-lines,” “toner,” “toner-2010,” “toner-2011,” “toner-background,” “toner-hybrid,” “toner-labels,” “toner-lines,” “toner-lite,” “watercolor.” The zoom parameter determines how detailed your base map will be: from 0 to 18 (high zoom levels — 12 and higher — will require more tiles downloaded, which will take more time). ggmap(get_stamenmap(bbox = c(bb_vienna), zoom = 12, maptype=&quot;terrain&quot;)) ggmap(get_stamenmap(bbox = c(bb_vienna), zoom = 12, maptype=&quot;toner&quot;)) ggmap(get_stamenmap(bbox = c(bb_vienna), zoom = 11, maptype=&quot;toner-lines&quot;)) ggmap(get_stamenmap(bbox = c(bb_vienna), zoom = 12, maptype=&quot;watercolor&quot;)) 8.5 Artistic Maps You might have seen beautiful maps of cities that are used as decorations. The following code (simplified from a blog post by Taras Kaduk, see Additional Materials) creates a nice looking map of Vienna. Your task will be to tweak this code and create two maps of cities of your choice. You may also consult Esteban Moro’s similar blogpost (see Additional Materials). It is better to run the following code as a script, not as a part of your notebook. You can then simply include your generated maps into your notebooks as images. You can also include the entire working code in the notebook: with these parameters — {r eval=FALSE, include=TRUE} — the code will be included, displayed in the final notebook, but it will not be executed during knitting. library(sf) library(osmdata) library(ggplot2) library(tidyverse) library(lwgeom) fileName &lt;- &quot;./path_to_save/Wien&quot; city &lt;- &quot;Wien&quot; # for map place &lt;- &quot;Vienna Austria&quot; # for search highway_sizes &lt;- tibble::tribble( ~highway, ~highway_group, ~size, &quot;motorway&quot;, &quot;large&quot;, 0.5, &quot;motorway_link&quot;, &quot;large&quot;, 0.3, &quot;primary&quot;, &quot;large&quot;, 0.5, &quot;primary_link&quot;, &quot;large&quot;, 0.3, &quot;secondary&quot;, &quot;medium&quot;, 0.3, &quot;secondary_link&quot;, &quot;medium&quot;, 0.3, &quot;tertiary&quot;, &quot;medium&quot;, 0.3, &quot;tertiary_link&quot;, &quot;medium&quot;, 0.3, &quot;residential&quot;, &quot;small&quot;, 0.2, &quot;living_street&quot;, &quot;small&quot;, 0.2, &quot;unclassified&quot;, &quot;small&quot;, 0.2, &quot;service&quot;, &quot;small&quot;, 0.2, &quot;footway&quot;, &quot;small&quot;, 0.2 ) streets_osm &lt;- opq(place) %&gt;% add_osm_feature(key = &quot;highway&quot;, value = highway_sizes$highway) %&gt;% osmdata_sf() streets &lt;- streets_osm$osm_lines %&gt;% dplyr::select(osm_id, name, name.en, highway, maxspeed, oneway, surface) %&gt;% mutate(length = as.numeric(st_length(.))) %&gt;% left_join(highway_sizes, by=&quot;highway&quot;) %&gt;% filter(highway_group != &quot;small&quot; | length &gt;= quantile(length, probs = 0.25)) railways_osm &lt;- opq(place) %&gt;% add_osm_feature(key = &quot;railway&quot;, value=&quot;rail&quot;) %&gt;% osmdata_sf() railways &lt;- railways_osm$osm_lines %&gt;% dplyr::select() river_osm &lt;- opq(place) %&gt;% add_osm_feature(key = &quot;waterway&quot;, value = c(&quot;river&quot;, &quot;riverbank&quot;)) %&gt;% osmdata_sf() %&gt;% unname_osmdata_sf() water_osm &lt;- opq(place) %&gt;% add_osm_feature(key = &quot;natural&quot;, value = c(&quot;water&quot;, &quot;wetland&quot;, &quot;bay&quot;)) %&gt;% osmdata_sf() %&gt;% unname_osmdata_sf() water &lt;- c(water_osm, river_osm) %&gt;% .$osm_multipolygons %&gt;% dplyr::select(osm_id, name) %&gt;% mutate(area = st_area(.)) %&gt;% # this filter gets rid of tiny isolated lakes et cetera filter(area &gt;= quantile(area, probs = 0.75)) bbox &lt;- opq(place)$bbox %&gt;% strsplit(&quot;,&quot;) %&gt;% unlist %&gt;% as.double blankbg &lt;-theme(axis.line=element_blank(), axis.text.x=element_blank(), axis.text.y=element_blank(), axis.ticks=element_blank(), axis.title.x=element_blank(), axis.title.y=element_blank(), legend.position = &quot;none&quot;, plot.background=element_blank(), panel.grid.minor=element_blank(), panel.background=element_blank(), panel.grid.major=element_blank(), plot.margin = unit(c(t=2,r=2,b=2,l=2), &quot;cm&quot;), plot.caption = element_text(color = &quot;grey20&quot;, size = 92, hjust = .5, face = &quot;plain&quot;, family = &quot;Willow&quot;), panel.border = element_blank() ) p &lt;- ggplot() + blankbg + geom_sf(fill=&quot;white&quot;, color=&quot;white&quot;) + geom_sf(data = water, fill = &quot;lightsteelblue2&quot;, lwd = 0, alpha = 1) + geom_sf(data = railways, color=&quot;grey30&quot;, size=.2, linetype=&quot;dotdash&quot;, alpha=.5) + geom_sf(data = streets %&gt;% filter(highway_group == &quot;small&quot;), size = .1, color = &quot;grey40&quot;) + geom_sf(data = streets %&gt;% filter(highway_group == &quot;medium&quot;), size = .3, color = &quot;grey35&quot;) + geom_sf(data = streets %&gt;%filter(highway_group == &quot;large&quot;), size = .5, color = &quot;grey30&quot;) + labs(caption = city) + coord_sf(xlim = c(bbox[2], bbox[4]), ylim = c(bbox[1], bbox[3]), expand = FALSE) ggsave(paste0(fileName,&quot;_Map.png&quot;), plot=p, width = 297, height = 420, units = &quot;mm&quot;, dpi = &quot;retina&quot;) 8.6 Homework Create at least two maps for regions (continents or clusters of countries) of your choice. Focus on how your map looks. Experiment with visual improvements; try to add more information and data. Create a couple of artistic maps for cities of your choice. Experiment with different elements — perhaps you can add additional data (points on places that are important to you; some other types of data, etc.) Submit your knitted notebook. 8.7 Additional Materials Kaduk, Taras (2021, Jan. 18). Print Personalized Street Maps Using R. Retrieved from: https://taraskaduk.com/posts/2021-01-18-print-street-maps/ Moro, Esteban (2020, Oct. 19). Personal Art Map with R. Retrieved from: http://estebanmoro.org/post/2020-10-19-personal-art-map-with-r/ Davis, Erin R. (2019, Jul. 19). The Beautiful Hidden Logic of Cities. Retrieved from: https://erdavis.com/2019/07/27/the-beautiful-hidden-logic-of-cities/ 8.8 Submitting homework Homework assignment must be submitted by the beginning of the next class; Email your homework to the instructor as attachments. In the subject of your email, please, add the following: 070184-LXX-HW-YourLastName-YourMatriculationNumber, where LXX is the numnber of the lesson for which you submit homework; YourLastName is your last name; and YourMatriculationNumber is your matriculation number. "],
["l09-gis-iii.html", "9 L09: GIS III 9.1 Mapping Categorical and Continuous Data 9.2 Maps 9.3 Homework 9.4 Submitting homework", " 9 L09: GIS III 9.1 Mapping Categorical and Continuous Data library(tidyverse) library(ggspatial) library(ggplot2) library(ggrepel) library(rnaturalearth) library(rnaturalearthdata) world &lt;- ne_countries(scale = &quot;medium&quot;, returnclass = &quot;sf&quot;) 9.1.1 Goals Basic strategies for mapping data. 9.1.2 Software R 9.1.3 Data library(historydata) library(europop) ## Warning: package &#39;europop&#39; was built under R version 4.0.2 #help(package = historydata) #help(package = europop) We will use data from packagess europop and historydata. 9.1.3.1 Some Vienna Data Source: https://www.data.gv.at/katalog/dataset/stadt-wien_bezirksgrenzenwien. Download SHP file. You can load it, using the following code. (The file must be unzipped: BEZIRKSGRENZEOGD is the default folder; BEZIRKSGRENZEOGDPolygon is the name of most files in the unzipped folder) map of districts of Vienna (SHP/shape file); population of Vienna (csv file) library(rgdal) # R wrapper around GDAL/OGR library(ggmap) # for fortifying shapefiles (converting GIS files into data frames) library(ggplot2) # ggplot2 library Loading SHP file, like we did before. plot() allows us to quickly assess whether data was loaded correctly. wienBezirks &lt;- readOGR(&quot;./data_temp/BEZIRKSGRENZEOGD&quot;, &quot;BEZIRKSGRENZEOGDPolygon&quot;) ## OGR data source with driver: ESRI Shapefile ## Source: &quot;/Users/romanovienna/Dropbox/6_Teaching_New/_rgis_course/rgis_univie2021_draft/data_temp/BEZIRKSGRENZEOGD&quot;, layer: &quot;BEZIRKSGRENZEOGDPolygon&quot; ## with 23 features ## It has 15 fields plot(wienBezirks) Loading our data on the growth of Vienna… library(readr) wienBezirksData &lt;- read_csv(&quot;data_temp/wien_data/Wien_Stadt_Data.csv&quot;) ## Parsed with column specification: ## cols( ## Bezirk_Nummer = col_character(), ## Bezirk_Name = col_character(), ## Kategorie = col_character(), ## Jahr = col_double(), ## Daten = col_double() ## ) head(wienBezirksData) ## # A tibble: 6 x 5 ## Bezirk_Nummer Bezirk_Name Kategorie Jahr Daten ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 11 Simmering Häuser 1590 207 ## 2 11 Simmering Häuser 1751 225 ## 3 11 Simmering Häuser 1783 281 ## 4 11 Simmering Häuser 1787 281 ## 5 11 Simmering Häuser 1794 329 ## 6 11 Simmering Häuser 1795 319 9.2 Maps 9.2.1 Choropleth: Population of Vienna over time Choropleth map is very commonly used to visualize spatial data. Polygons are colored and the intensity of color (or change from one color to another with some color scale) is used to indicate continuous values Less frequently, this type of maps is also used for categorical data. fortify is a function that converts a coomplex SHP object into a dataframe that ggplot2 can understand; parameter region is important — here you assign data from which column of the original shape file must be associated with the elements in new dataframe. We want to associate all polygons with districts (BEZ contains district numbers — in the same format as we have in wienBezirksData: 01, 02, 03, etc.). The operation is quite simple, but crucial. wienBezirksMod &lt;- fortify(wienBezirks, region = &quot;BEZ&quot;) Now, we need to process somme data and then we can map it with ggplot. In the chunk below we simply pick data for a specific year. wienBezirksDataTemp &lt;- wienBezirksData %&gt;% filter(Kategorie==&quot;Einwohner&quot; &amp; Jahr == 2011) Now, for adding labels to our map, we need to generate coordinates for where those labels will be added. The following chunk calculated average mean of all latitude and longitude values for each district. distcenters &lt;- wienBezirksMod %&gt;% group_by(id) %&gt;% dplyr::summarize(clat = mean(lat), clong = mean(long)) %&gt;% left_join(wienBezirksData, by = c(&quot;id&quot; = &quot;Bezirk_Nummer&quot;)) %&gt;% select(id, clat, clong, Bezirk_Name) %&gt;% unique %&gt;% mutate(label = paste0(id, &quot;. &quot;, Bezirk_Name)) Now we can put everything on the graph. ggplot() + geom_map(data = wienBezirksDataTemp, aes(map_id = Bezirk_Nummer, fill = Daten), map = wienBezirksMod) + expand_limits(x = wienBezirksMod$long, y = wienBezirksMod$lat) + geom_text_repel(data = distcenters, aes(x = clong, y = clat, label = label), size = 2) + scale_fill_gradient(low = &quot;white&quot;, high = &quot;red&quot;, na.value = NA) + labs(title=&quot;Population of Vienna, 2011&quot;, x =&quot;&quot;, y = &quot;&quot;) As you already know, we can generate multiple maps to visualize different aspects of our data. With of Viennese data, we can generate graphs by years. wienBezirksDataTemp &lt;- wienBezirksData %&gt;% filter(Kategorie==&quot;Einwohner&quot; &amp; Jahr &gt;= 1857) %&gt;% filter(Jahr != 1864) ggplot() + geom_map(data = wienBezirksDataTemp, aes(map_id = Bezirk_Nummer, fill = Daten), map = wienBezirksMod) + expand_limits(x = wienBezirksMod$long, y = wienBezirksMod$lat) + scale_fill_gradient2(low = &quot;white&quot;, mid=&quot;yellow&quot;, high = &quot;red&quot;, na.value = NA) + facet_wrap(~ Jahr) + labs(title=&quot;Growth of Vienna, 1857-2011&quot;, x =&quot;&quot;, y = &quot;&quot;) Advantages and drawbacks of choroplleth maps? Homework: generate similar maps for the growth of the US (of the state level), using data from historydata. You will need to preprocess data properly. Also, feel free to experiment with the visual parameters. Use help or google for more details. Additional Materials: http://bl.ocks.org/prabhasp/raw/5030005/ https://socviz.co/maps.html https://rkabacoff.github.io/datavis/GeoMaps.html 9.2.2 Dots: Population Growth - US population (by city) In some (or, probably, most) cases, it might be better to avoid choropleth maps. Instead, we can use dots sized with specific parameters. But first, let’s prepare our base layer. waterColor = &quot;lightsteelblue2&quot; xlim=c(-140, -50); ylim=c(20,55) baseplot &lt;- ggplot(data = world) + geom_sf(fill=&quot;white&quot;, color=&quot;white&quot;) + coord_sf(xlim = xlim, ylim = ylim, expand = FALSE) themeParameters &lt;- theme(panel.background = element_rect(fill = waterColor), axis.title.y=element_blank(), axis.title.x=element_blank(), axis.text.x=element_blank(), axis.ticks.x=element_blank(), axis.text.y=element_blank(), axis.ticks.y=element_blank(), panel.grid.major = element_line(color = waterColor, linetype = &quot;dotted&quot;, size = 0.5)) baseplot + themeParameters Homework: update this map by adding lakes and rivers. (See the previous lesson to refresh how this can be done.) Let’s try to add some historical data: us_cities_pop dataset gives us data by decades. us_data &lt;- historydata::us_cities_pop %&gt;% filter(year &gt;= 1790 &amp; year &lt;= 1900) baseplot + geom_point(data = us_data, aes(x=lon, y=lat, size=population), alpha = 0.02) + scale_size_continuous(range = c(0.05, 3)) + facet_wrap(~ year) + labs(title=&quot;Growth of the USA, 1790-1900&quot;, x =&quot;&quot;, y = &quot;&quot;) + themeParameters us_data &lt;- historydata::us_cities_pop %&gt;% filter(year &gt;= 1900) baseplot + geom_point(data = us_data, aes(x=lon, y=lat, size=population), alpha = 0.02) + scale_size_continuous(range = c(0.05, 3)) + facet_wrap(~ year) + labs(title=&quot;Growth of the USA, 1900-2010&quot;, x =&quot;&quot;, y = &quot;&quot;) + themeParameters This kind of maps give a nice insight into such processes as growth of territories. Dots, of course, can be used to map any quantitative parameter. 9.2.3 Graphs: Population Growth by State Sometimes, however, we might opt out of using maps. Package geofacet (more on this package) offers a differnt approach: it offers the use of suggestive tables instead of maps. Below you can find a code sample that visualizes the same data as we had above. #install.packages(&quot;geofacet&quot;) library(geofacet) ## Warning: package &#39;geofacet&#39; was built under R version 4.0.2 us_states_pop &lt;- historydata::us_cities_pop %&gt;% group_by(state, year) %&gt;% dplyr::summarize(population = sum(population)) ## `summarise()` has grouped output by &#39;state&#39;. You can override using the `.groups` argument. graph01 &lt;- ggplot(us_states_pop, aes(year, population)) + geom_line() + facet_geo(~ state, grid = &quot;us_state_grid2&quot;, label = &quot;name&quot;) + labs(title = &quot;Growth of the US, 1790-2010&quot;, caption = &quot;Data Source: `historydata`&quot;, x = &quot;Year&quot;, y = &quot;Population&quot;) + theme(axis.text.x = element_text(angle = 90)) ## Some values in the specified facet_geo column &#39;state&#39; do not match the ## &#39;code&#39; column of the specified grid and will be removed: IT ggsave(&quot;us_facet_map.png&quot;, plot=graph01, width = 400, height = 200, units = &quot;mm&quot;, dpi = &quot;retina&quot;) Homework: check documentation on geofacet (https://cran.r-project.org/web/packages/geofacet/vignettes/geofacet.html). The package has an interface to develop custom grid. Develop a grid for Viennese districts and plot the growth of their population using your custom grid. Grid designer is available here: https://hafen.github.io/grid-designer/. You will need some data for an easy start: wien_starting_grid &lt;- distcenters %&gt;% mutate(row = seq(1,23), col=seq(1,23)) %&gt;% mutate(code = id, name = label) %&gt;% select(row,col,code,name) You can start it with the following line of code: grid_design(data = wien_starting_grid, img = &quot;https://upload.wikimedia.org/wikipedia/commons/thumb/1/1f/Vienna%2C_administrative_divisions_-_Nmbrs.svg/2880px-Vienna%2C_administrative_divisions_-_Nmbrs.svg.png&quot;) mygrid &lt;- data.frame( row = c(5, 4, 4, 4, 5, 5, 6, 6, 6, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23), col = c(9, 9, 8, 7, 8, 7, 9, 8, 7, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23), code = c(&quot;02&quot;, &quot;09&quot;, &quot;08&quot;, &quot;07&quot;, &quot;01&quot;, &quot;06&quot;, &quot;03&quot;, &quot;04&quot;, &quot;05&quot;, &quot;10&quot;, &quot;11&quot;, &quot;12&quot;, &quot;13&quot;, &quot;14&quot;, &quot;15&quot;, &quot;16&quot;, &quot;17&quot;, &quot;18&quot;, &quot;19&quot;, &quot;20&quot;, &quot;21&quot;, &quot;22&quot;, &quot;23&quot;), name = c(&quot;02. Leopoldstadt&quot;, &quot;09. Alsergrund&quot;, &quot;08. Josefstadt&quot;, &quot;07. Neubau&quot;, &quot;01. Innere-Stadt&quot;, &quot;06. Mariahilf&quot;, &quot;03. Landstraße&quot;, &quot;04. Wieden&quot;, &quot;05. Margareten&quot;, &quot;10. Favoriten&quot;, &quot;11. Simmering&quot;, &quot;12. Meidling&quot;, &quot;13. Hietzing&quot;, &quot;14. Penzing&quot;, &quot;15. Rudolfsheim-Fünfhaus&quot;, &quot;16. Ottakring&quot;, &quot;17. Hernals&quot;, &quot;18. Währing&quot;, &quot;19. Döbling&quot;, &quot;20. Brigittenau&quot;, &quot;21. Floridsdorf&quot;, &quot;22. Donaustadt&quot;, &quot;23. Liesing&quot;), stringsAsFactors = FALSE ) geofacet::grid_preview(mygrid) ## Note: You provided a user-specified grid. If this is a generally-useful ## grid, please consider submitting it to become a part of the geofacet ## package. You can do this easily by calling: ## grid_submit(__grid_df_name__) Optional: complete the same task for the europop dataset (library europop). 9.2.4 Many Maps: Population by city — growth of the US You might need to generate multiple high-resolution maps, instead of a set of tiny faceted maps. For this purpose loops are very helpful. They are a powerful tool and one should know how to use them. Below is an example of a very simple for loop. The our loop prints single letters—one after another—from a built-in vector/variable letters. (as you might remember from the early worksheets, letters is a built-in vector of English letters.) string &lt;- &quot;This is letter&quot; for(l in letters){ print(paste(string, l)) } ## [1] &quot;This is letter a&quot; ## [1] &quot;This is letter b&quot; ## [1] &quot;This is letter c&quot; ## [1] &quot;This is letter d&quot; ## [1] &quot;This is letter e&quot; ## [1] &quot;This is letter f&quot; ## [1] &quot;This is letter g&quot; ## [1] &quot;This is letter h&quot; ## [1] &quot;This is letter i&quot; ## [1] &quot;This is letter j&quot; ## [1] &quot;This is letter k&quot; ## [1] &quot;This is letter l&quot; ## [1] &quot;This is letter m&quot; ## [1] &quot;This is letter n&quot; ## [1] &quot;This is letter o&quot; ## [1] &quot;This is letter p&quot; ## [1] &quot;This is letter q&quot; ## [1] &quot;This is letter r&quot; ## [1] &quot;This is letter s&quot; ## [1] &quot;This is letter t&quot; ## [1] &quot;This is letter u&quot; ## [1] &quot;This is letter v&quot; ## [1] &quot;This is letter w&quot; ## [1] &quot;This is letter x&quot; ## [1] &quot;This is letter y&quot; ## [1] &quot;This is letter z&quot; We can use the same strategy to loop over some table of our data and generate maps based on the changing parameter. For example, we want to generate maps of U.S. cities, where each map would show us data forr a specific decade. Let’s try a simple example first: let’s generate headers for our future maps. us_data &lt;- historydata::us_cities_pop decades &lt;- unique(us_data$year) for (d in decades){ header &lt;- paste0(&quot;U.S. cities in &quot;, d) print(header) } ## [1] &quot;U.S. cities in 1790&quot; ## [1] &quot;U.S. cities in 1800&quot; ## [1] &quot;U.S. cities in 1810&quot; ## [1] &quot;U.S. cities in 1820&quot; ## [1] &quot;U.S. cities in 1830&quot; ## [1] &quot;U.S. cities in 1840&quot; ## [1] &quot;U.S. cities in 1850&quot; ## [1] &quot;U.S. cities in 1860&quot; ## [1] &quot;U.S. cities in 1870&quot; ## [1] &quot;U.S. cities in 1880&quot; ## [1] &quot;U.S. cities in 1890&quot; ## [1] &quot;U.S. cities in 1900&quot; ## [1] &quot;U.S. cities in 1910&quot; ## [1] &quot;U.S. cities in 1920&quot; ## [1] &quot;U.S. cities in 1930&quot; ## [1] &quot;U.S. cities in 1940&quot; ## [1] &quot;U.S. cities in 1950&quot; ## [1] &quot;U.S. cities in 1960&quot; ## [1] &quot;U.S. cities in 1970&quot; ## [1] &quot;U.S. cities in 1980&quot; ## [1] &quot;U.S. cities in 1990&quot; ## [1] &quot;U.S. cities in 2000&quot; ## [1] &quot;U.S. cities in 2010&quot; Now we can modify this code so that it generates maps: us_data &lt;- historydata::us_cities_pop decades &lt;- unique(us_data$year) for (d in decades){ header &lt;- paste0(&quot;U.S. cities in &quot;, d) dataTemp &lt;- us_data %&gt;% filter(year == d) mapTemp &lt;- baseplot + geom_point(data = dataTemp, aes(x=lon, y=lat, size=population), alpha = 0.5) + scale_size_continuous(range = c(0.05, 5)) + labs(title=header, x =&quot;&quot;, y = &quot;&quot;) + themeParameters ggsave(paste0(&quot;us_map_&quot;, d, &quot;.png&quot;), plot=mapTemp, width = 400, height = 200, units = &quot;mm&quot;, dpi = &quot;retina&quot;) } Here are some results: Homework: generate similar maps from europop data. 9.2.5 Animated Maps: Population by city — growth of the US One last ting for today: animated maps. Package gganimate is a great tool fo rcreating animated graphs and maps. #install.packages(&#39;gganimate&#39;) library(gganimate) ## Warning: package &#39;gganimate&#39; was built under R version 4.0.2 us_data &lt;- historydata::us_cities_pop Let’s start with a static plot, but first we need to prepare data. If our data is not prepared properly, our results may be very weird. Like on the map below: Essentially, to avoid that we need to prepare data for each frame of our future animation. Our data is given for every 10th year (1790, 1800, 1810, etc.). gganimiate tries to fill in the blanks by creation transition frames. In other words, only every 10th frame shows the real data. There are multiple ways of how this issue can be solved. In the code below we create values for missing years — the value of each 10th year is assigned to years 11, 12, 13, etc. We use a for-loop for this. waterColor = &quot;lightsteelblue2&quot; xlim=c(-130, -60); ylim=c(23,52) us_data_filtered &lt;- us_data %&gt;% filter(between(lon, xlim[1], xlim[2])) %&gt;% filter(between(lat, ylim[1], ylim[2])) us_data_filtered_enriched &lt;- us_data_filtered for (n in seq(1,9)){ temp &lt;- us_data_filtered %&gt;% mutate(year = year + n) us_data_filtered_enriched &lt;- add_row(us_data_filtered_enriched, temp) } us_data_filtered_enriched &lt;- us_data_filtered_enriched %&gt;% filter(year &lt;= 2010) Now, the plot: baseplot &lt;- ggplot(data = world) + geom_sf(fill=&quot;white&quot;, color=&quot;white&quot;) + coord_sf(xlim = xlim, ylim = ylim, expand = FALSE) usMap &lt;- baseplot + geom_point(data = us_data_filtered_enriched, aes(x=lon, y=lat, size = population), alpha = 0.1, show.legend = FALSE) + scale_size_continuous(range = c(0.05, 5)) + themeParameters usMap Now, the following code animates our map. And the last line saves our animation into a file. Check documentation for gganimate for many other options for saving animations. NB: Keep in mind that this process make take a while, so you do not want to rerun it every time you knit your notebook! usMapAnimated &lt;- usMap + transition_time(year) + labs(title = &quot;Growth of the US cities: {frame_time}&quot;) anim_save(&quot;usMap_Animated.gif&quot;, animation=usMapAnimated, end_pause = 10, rewind = FALSE, height = 5, width = 8, units = &quot;in&quot;, res = 300) This is our animated map, which we saved into a gif file. Homework: Animate any of the maps that you are tasked to prepare above. 9.3 Homework Homework is described in the lesson. Submit your knitted notebook. 9.4 Submitting homework Homework assignment must be submitted by the beginning of the next class; Email your homework to the instructor as attachments. In the subject of your email, please, add the following: 070184-LXX-HW-YourLastName-YourMatriculationNumber, where LXX is the numnber of the lesson for which you submit homework; YourLastName is your last name; and YourMatriculationNumber is your matriculation number. "],
["l10-gis-iv.html", "10 L10: GIS IV 10.1 Mapping Networks 10.2 Goals 10.3 Software 10.4 Networks 10.5 Additional Materials on Networks in R 10.6 Homework 10.7 Submitting homework", " 10 L10: GIS IV 10.1 Mapping Networks Coming soon 10.2 Goals Basic understanding of networks Data for networks: nodes and edges Modeling networks Most common approaches 10.3 Software R, RStudio igraph and a few other new libraries NB: igraph is the main SNA library. There are other packages we can use to visualize graphs (ggraph, for example), but most calculations and the overall analysis is still to be performed with igraph. You can get an overview of its contents with library(help=\"igraph\"). More information: https://igraph.org/r/; full documentation: https://igraph.org/r/doc/igraph.pdf Data: Our practice datasets will include two data sets on Islamic history: 1) the route network of the islamic world around 9-10th centuries (https://althurayya.github.io/); and bio-geographical data collected from 30,000 medieval biographies (Source: “The History of Islam” (Taʾrīḫ al-islām) of al-Ḏahabī (748/1348 CE)): Islamic_World_Data.zip # General ones library(tidyverse) library(readr) library(stringr) library(ggplot2) # SNA Specific library(igraph) library(ggraph) library(ggrepel) library(ggalt) # mapping library(rnaturalearth) library(rnaturalearthdata) library(grid) # grid library cuts out the plot from the graph 10.4 Networks 10.4.1 Basic Concepts Example networks: make a simple network of Vienna districts explain how networks could work on hypothetical people living in different Viennese districts person, district, dates (1800-2000), political views (Party 1, Party 2, Party 1) need some very small network, through which I can explain things. Data on Vienna: https://www.geschichtewiki.wien.gv.at/Personen_Zeitleiste ; http://www.dasrotewien.at/ Basics of networks: nodes and edges the roles of nodes and edges Main measures: centrality betweenness clusters and cliques A note on: unimodal (only one types of nodes), bimodal, and multimodal networks gist of it: one should always find ways to convert data into unimodal networks, as this is the type of networks that most algorithms are designed to work with; bimodal network can be converted into unimodal one by converting the second type of nodes into edges and their values. bimodal network: nodes are individuals and cities, edges — connections of individuals to cities; connections of cities to cities; connections of individuals to individuals (potentially) unimodal: nodes are individuals; edges are shared cities individuals are connected with/to. Thus, in this case, connections between two individuals become a shared city they are connected to; the weight of this connection may be based on a number of shared cities. In other words, the connection between two individuals that share ten same cities will be stronger than between individuals that share only one; and there will be no connection between individuals who share no common cities. unimodal network: one type of nodes; one type of connections; that said, the weight of connections may be aggregated from multiple parameters. For example, we have three individuals who share the city of Vienna as their connection; however, person 1 and person 2 also share something else — a district; the period of their lives overlap, etc., while person 1 and person 3 lived in different districts and their lives did not overlap chronologically. Thus, the weight of the edge between person 1 and 2 will be larger, than between 1 and 3 and two and 3. Yet, if there is also person 4, who has no connection to Vienna, his/her connection to P1, P2, and P3 will be nonexistent, unless we consider other parameters for the edges (shared lifetime, for example; or, larger geographical entities, etc.) 10.4.2 Data for Networks: Nodes and Edges Nodes Edges 10.4.3 Modeling a Network … 10.4.4 Most common analytical steps: some recipes 10.4.4.1 Basemap Download this file with extra data layers: map_objects.zip. Unzip it and make sure to change the path in the code below so that you can load the data. RDSfolder=&quot;./data_temp/map_objects/&quot; rivers_df &lt;- readRDS(paste0(RDSfolder,&quot;rivers_df.rds&quot;)) aral_sea_df &lt;- readRDS(paste0(RDSfolder,&quot;aral_sea_df.rds&quot;)) routes_df &lt;- readRDS(paste0(RDSfolder,&quot;routes_df.rds&quot;)) Now, le’t create a base layer map, as we did before: NB: to install rnaturalearthhires, you may need to run: remotes::install_github(\"ropensci/rnaturalearthhires\") Base layer for the medieval Islamic world: world &lt;- ne_countries(scale=&quot;medium&quot;, returnclass=&quot;sf&quot;) colWater= &quot;lightsteelblue2&quot; colLand = &quot;white&quot; colRout = &quot;grey&quot; xlimVal=c(-12,80); ylimVal=c(10,50) IslamicWorldBase &lt;- ggplot(data=world) + geom_sf(fill=colLand, color=colLand) + # rivers, aral sea, and routes geom_path(data=routes_df, aes(x=long, y=lat, group=id), color=colRout, size=.2) + geom_path(data=rivers_df, aes(x=long, y=lat, group=group), color=colWater, alpha=1, size=.3) + geom_polygon(data=aral_sea_df, aes(x=long, y=lat, group=group), color=colWater, fill=colWater, size=.2) + # map limits and theme #coord_sf(xlim=xlimVal, ylim=ylimVal, expand=FALSE) + theme(panel.grid.major=element_line(color=colWater, linetype=&quot;dotted&quot;, size=0.5), panel.background=element_rect(fill=colWater),legend.position=&quot;none&quot;, panel.border=element_blank()) # ANNOTATION VARIABLES mainAlpha=.75 headColor=&quot;grey30&quot; textColor=&quot;grey10&quot; # ANNOTATION LAYERS # TR (Top-Right) - Descriptions #X=79; Y=49.25; Ystep=3 #IslamicWorldBase &lt;- IslamicWorldBase+ # annotate(&quot;text&quot;,label=&quot;https://althurayya.github.io/&quot;, x=X,y=Y,angle=0,hjust=1,vjust=1,size=4,col=textColor,alpha=mainAlpha, family=fontVal) IslamicWorldBase Routes are plotted in grey; rivers — in blue. We will not modify routes in any way with additional data for visualization. Let’s now load network data, which will include the following: nodes will be settlements; edges will be “routes” that we see on the map, but we will use only values, not the “drawings” of these routes for our analysis. More specifically, our edges data will include connections between places. Here we will need some additional steps. Let’s load edges first, as they are rather simple (download: althurayya.zip). There is a lot of data that we will not need, so I will filter it out, edges &lt;- read_delim(&quot;./data_temp/althurayya/routes.csv&quot;, &quot;\\t&quot;, escape_double = FALSE, trim_ws = TRUE) edges &lt;- edges %&gt;% mutate(weight = meter) %&gt;% select(sToponym, eToponym, weight, meter, terrain, safety) head(edges) ## # A tibble: 6 x 6 ## sToponym eToponym weight meter terrain safety ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; ## 1 RIHA_354E318N_S NABULUS_352E322N_S 48742 48742 mountain safe ## 2 ZARQA_360E320N_S AMMAN_359E319N_S 22288 22288 river dangerous ## 3 ZARQA_360E320N_S ADHRIAT_360E326N_S 67802 67802 desert normal ## 4 ADHRIAT_360E326N_S ZARQA_360E320N_S 61334 61334 mountain dangerous ## 5 NAWA_360E328N_S ADHRIAT_360E326N_S 31554 31554 normal safe ## 6 JASIM_360E329N_S AQABAFIQ_356E327N_S 41808 41808 mountain safe Here we have sToponym, eToponym, and meter, i.e. the distance from the start-place to the end-place. The “start” and the “end” do not really carry any meaning here as the network is undirected. We will use the values from meter as weight for now. Below, we will discuss how these values may be modeled in order to make your network more nuanced. Now, the nodes: nodes &lt;- read_delim(&quot;./data_temp/althurayya/settlements.csv&quot;, &quot;\\t&quot;, escape_double = FALSE, trim_ws = TRUE) nodes &lt;- nodes %&gt;% separate(col=coordinates, into=c(&quot;l&quot;, &quot;lon&quot;, &quot;lat&quot;, &quot;r&quot;), sep=&quot;([\\\\[, \\\\]]+)&quot;) %&gt;% select(settlement_id, names_eng_translit, region_URI, top_type, lon, lat) %&gt;% mutate(lon = as.numeric(lon), lat = as.numeric(lat)) # remove nodes which are not in the network nwNodes &lt;- unique(c(edges$sToponym, edges$eToponym)) nodes &lt;- nodes %&gt;% filter(settlement_id %in% nwNodes) head(nodes) ## # A tibble: 6 x 6 ## settlement_id names_eng_translit region_URI top_type lon lat ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 QAHIRA_312E300N_S al-Qāhiraŧ Misr_RE metropoles 31.2 30.0 ## 2 WASHQA_003W421N_S Wašqaŧ Andalus_RE towns -0.354 42.2 ## 3 BALANSIYYA_004W394N_S Balansiyyaŧ Andalus_RE towns -0.415 39.4 ## 4 SHAQR_004W391N_S al-Šaqr Andalus_RE villages -0.437 39.2 ## 5 QANT_004W383N_S Qānt Andalus_RE towns -0.471 38.3 ## 6 SHATIBA_005W389N_S Šātibaŧ Andalus_RE towns -0.523 39.0 Let’s quickly generate a map with our nodes — so that you have a general idea: nodesTop &lt;- nodes %&gt;% filter(top_type == &quot;metropoles&quot;) annotData &lt;- nodesTop metropoles &lt;- IslamicWorldBase + geom_point(data = nodes, aes(x=lon, y=lat, col=region_URI), alpha=1, size=0.25) + geom_point(data = annotData, aes(x=lon, y=lat), col=&quot;red&quot;, size=1) + geom_label_repel(data = annotData, aes(label = names_eng_translit, x=lon, y=lat)) + coord_sf(xlim=c(min(nodes$lon)-1, max(nodes$lon)+1), ylim=c(min(nodes$lat)-1, max(nodes$lat)+1), expand=FALSE) metropoles The following lines of code will help you to save your maps without unnecessary information — cut out and keep only the map. There may still be white stripes on the sides, so you may have to need to play around with the width and height parameters. gt &lt;- ggplot_gtable(ggplot_build(metropoles)) ge &lt;- subset(gt$layout, name == &quot;panel&quot;) ggsave(file=paste0(&quot;./files/networks/IW_metropoles.png&quot;), # the following line focuses on the graph plot=grid.draw(gt[ge$t:ge$b, ge$l:ge$r]), # width and height should be experimentally adjusted to remove white space dpi=300,width=8.4,height=4.65) Note: Colors of dots on this map indicate different provinces of the early Islamic world. Considering that borders—in the modern sense—did not exist back then, this is one of the most efficient ways of displaying the extents of regions. White areas effectively indicate uninhabited lands—in most cases, deserts, mountains, or mountainous deserts. 10.4.5 The Network Now, as we have both the nodes and the edges, we can start our analysis. There are a few things that make sense to begin with: look for the most important nodes in the network: i.e. those nodes, through which most other nodes are connected to each other (in practical terms that would mean that most people would travel through those places and, as a result, we may expect that these places would play an important role in cultural exchange); this analysis can be done in a variety of ways—we can use the network as is, or we can apply a variety of modifications that would help us to “encode” some additional historical information that might be missing from the network. By and large, this includes different centrality measures (degree, betweenness, eigenvector centrality, etc.); look for most closely interconnected clusters of nodes, which may may help us to understand the historical confines of specific areas, such as provinces, states, conquered territories and the like; look for the shortest paths within the network (i.e., how one would travel from one place to another); and, if we have relevant data, we can “overplot” other networks on geographical maps (movements of people); in this case, however, the network will be different and we will simply use the map as its layout. We start by creating a network object in the following manner: library(igraph) iwNetwork &lt;- graph_from_data_frame(d=edges, vertices=nodes, directed=FALSE) iwNetwork ## IGRAPH fd1ffa8 UNW- 1692 2053 -- ## + attr: name (v/c), names_eng_translit (v/c), region_URI (v/c), ## | top_type (v/c), lon (v/n), lat (v/n), weight (e/n) ## + edges from fd1ffa8 (vertex names): ## [1] NABULUS_352E322N_S --RIHA_354E318N_S ## [2] AMMAN_359E319N_S --ZARQA_360E320N_S ## [3] ZARQA_360E320N_S --ADHRIAT_360E326N_S ## [4] ZARQA_360E320N_S --ADHRIAT_360E326N_S ## [5] NAWA_360E328N_S --ADHRIAT_360E326N_S ## [6] AQABAFIQ_356E327N_S--JASIM_360E329N_S ## [7] NAWA_360E328N_S --JABIYA_360E329N_S ## + ... omitted several edges The description of an igraph object starts with four letters (in our case: UNW-): D or U, for a directed or undirected graph N for a named graph (where nodes have a name attribute) W for a weighted graph (where edges have a weight attribute) B for a bipartite (two-mode) graph (where nodes have a type attribute) In our case, it is UNW-, i.e.: undirected, named, weighted, and not bipartite. The two numbers that follow (110 444) refer to the number of nodes and edges in the graph. The description also lists node &amp; edge attributes, for example: (g/c) - graph-level character attribute (v/c) - vertex-level character attribute (e/n) - edge-level numeric attribute igraph objects provide us with an easy access to nodes, edges, and their attributes with the following commands: head(E(iwNetwork), 20) ## + 20/2053 edges from fd1ffa8 (vertex names): ## [1] NABULUS_352E322N_S --RIHA_354E318N_S ## [2] AMMAN_359E319N_S --ZARQA_360E320N_S ## [3] ZARQA_360E320N_S --ADHRIAT_360E326N_S ## [4] ZARQA_360E320N_S --ADHRIAT_360E326N_S ## [5] NAWA_360E328N_S --ADHRIAT_360E326N_S ## [6] AQABAFIQ_356E327N_S --JASIM_360E329N_S ## [7] NAWA_360E328N_S --JABIYA_360E329N_S ## [8] JABIYA_360E329N_S --JASIM_360E329N_S ## [9] ADHRIAT_360E326N_S --ROUTPOINT0121_362E333N_O ## [10] JASIM_360E329N_S --ROUTPOINT0121_362E333N_O ## + ... omitted several edges head(V(iwNetwork), 20) ## + 20/1692 vertices, named, from fd1ffa8: ## [1] QAHIRA_312E300N_S WASHQA_003W421N_S BALANSIYYA_004W394N_S ## [4] SHAQR_004W391N_S QANT_004W383N_S SHATIBA_005W389N_S ## [7] SARAQUSA_009W416N_S MURSIYA_011W379N_S TUTILA_016W420N_S ## [10] LURQA_017W376N_S MADINASALIM_024W411N_S BAJJANA_024W369N_S ## [13] MARIYYA_025W368N_S WADIHIJARA_031W406N_S WADIYASH_031W373N_S ## [16] BAYYASA_034W379N_S GHARNATA_035W372N_S LIBIRA_036W372N_S ## [19] QALARABAH_037W388N_S JAYYAN_038W377N_S head(E(iwNetwork)$weight, 20) ## [1] 48742 22288 67802 61334 31554 41808 5016 6380 81803 42594 ## [11] 97452 188149 43254 84816 47117 19536 24577 78493 28113 65632 head(V(iwNetwork)$name, 20) ## [1] &quot;QAHIRA_312E300N_S&quot; &quot;WASHQA_003W421N_S&quot; &quot;BALANSIYYA_004W394N_S&quot; ## [4] &quot;SHAQR_004W391N_S&quot; &quot;QANT_004W383N_S&quot; &quot;SHATIBA_005W389N_S&quot; ## [7] &quot;SARAQUSA_009W416N_S&quot; &quot;MURSIYA_011W379N_S&quot; &quot;TUTILA_016W420N_S&quot; ## [10] &quot;LURQA_017W376N_S&quot; &quot;MADINASALIM_024W411N_S&quot; &quot;BAJJANA_024W369N_S&quot; ## [13] &quot;MARIYYA_025W368N_S&quot; &quot;WADIHIJARA_031W406N_S&quot; &quot;WADIYASH_031W373N_S&quot; ## [16] &quot;BAYYASA_034W379N_S&quot; &quot;GHARNATA_035W372N_S&quot; &quot;LIBIRA_036W372N_S&quot; ## [19] &quot;QALARABAH_037W388N_S&quot; &quot;JAYYAN_038W377N_S&quot; Keep these commands in mind because they will help you to extract necessary information from graph objects that you create with igraph and reuse them elsewhere. 10.4.6 Measures of centrality Now we have our network object in the variable called iwNetwork and we can calculate several most common measures of centrality. They should tell us something about the structure of the network and the role of specific nodes. 10.4.6.1 Degree V(iwNetwork)$degree &lt;- degree(iwNetwork, mode=&quot;all&quot;) degree(iwNetwork, mode=&quot;all&quot;, loops=FALSE) %&gt;% sort(decreasing=TRUE) %&gt;% .[1:15] ## SHIRAZ_525E296N_S NAYSABUR_587E361N_S RAMLA_348E319N_S ## 8 8 8 ## HAMADHAN_485E347N_S BUKHARA_644E398N_S ISHBILIYYA_059W374N_S ## 7 7 6 ## MALATIN_383E383N_S RAQQA_390E359N_S MAKKA_398E213N_S ## 6 6 6 ## RAYY_515E356N_S SIRJAN_557E294N_S AMMAN_359E319N_S ## 6 6 6 ## SAMARQAND_670E396N_S HARRAN_390E368N_S KHANUQA_398E357N_S ## 6 5 5 hist(degree(iwNetwork, mode=&quot;all&quot;, loops=FALSE)) Let’s map this: highDegreeNodes &lt;- as_data_frame(iwNetwork, what=&quot;vertices&quot;) %&gt;% filter(degree &gt;= 5) %&gt;% filter(top_type != &quot;xroads&quot;) annotData &lt;- highDegreeNodes currentMap &lt;- IslamicWorldBase + geom_point(data = nodes, aes(x=lon, y=lat), col=&quot;grey&quot;, alpha=0.5, size=0.25) + geom_point(data = annotData, aes(x=lon, y=lat), col=&quot;red&quot;, size=1) + geom_label_repel(data = annotData, aes(label = names_eng_translit, x=lon, y=lat), max.overlaps = 100) + coord_sf(xlim=c(min(nodes$lon)-1, max(nodes$lon)+1), ylim=c(min(nodes$lat)-1, max(nodes$lat)+1), expand=FALSE) gt &lt;- ggplot_gtable(ggplot_build(currentMap)) ge &lt;- subset(gt$layout, name == &quot;panel&quot;) ggsave(file=paste0(&quot;./files/networks/IW_degree.png&quot;), # the following line focuses on the graph plot=grid.draw(gt[ge$t:ge$b, ge$l:ge$r]), # width and height should be experimentally adjusted to remove white space dpi=300,width=8.4,height=4.65) Interpretation: … 10.4.6.2 Eigenvector centrality V(iwNetwork)$eigenvectorNA &lt;- eigen_centrality(iwNetwork, directed=FALSE, weights=NA)$vector eigen_centrality(iwNetwork, directed=FALSE, weights=NA)$vector %&gt;% sort(decreasing=TRUE) %&gt;% .[1:15] ## RAMLA_348E319N_S ROUTPOINT0113_351E319N_O LUDD_348E319N_S ## 1.0000000 0.5393596 0.5387790 ## ROUTPOINT0112_346E318N_O ROUTPOINT0104_350E316N_O ROUTPOINT0109_345E315N_O ## 0.5387322 0.4385162 0.4333438 ## YAFA_347E320N_S NABULUS_352E322N_S YUBNA_347E318N_S ## 0.4260120 0.4080765 0.3684604 ## ROUTPOINT0111_346E318N_O ARSUF_348E321N_S ROUTPOINT0106_353E318N_O ## 0.3308589 0.3287425 0.2773982 ## KAFARSABA_348E321N_S QALANSUWA_349E322N_S BAYTMAQDIS_352E317N_S ## 0.2741019 0.2638621 0.2626629 hist(eigen_centrality(iwNetwork, directed=FALSE, weights=NA)$vector) Let’s map this: eigen &lt;- as_data_frame(iwNetwork, what=&quot;vertices&quot;) %&gt;% slice_max(eigenvectorNA, n = 15) %&gt;% filter(top_type != &quot;xroads&quot;) annotData &lt;- eigen currentMap &lt;- IslamicWorldBase + geom_point(data = nodes, aes(x=lon, y=lat), col=&quot;grey&quot;, alpha=0.5, size=0.25) + geom_point(data = annotData, aes(x=lon, y=lat), col=&quot;red&quot;, size=1) + geom_label_repel(data = annotData, aes(label = names_eng_translit, x=lon, y=lat), max.overlaps = 100) + coord_sf(xlim=c(min(nodes$lon)-1, max(nodes$lon)+1), ylim=c(min(nodes$lat)-1, max(nodes$lat)+1), expand=FALSE) gt &lt;- ggplot_gtable(ggplot_build(currentMap)) ge &lt;- subset(gt$layout, name == &quot;panel&quot;) ggsave(file=paste0(&quot;./files/networks/IW_eigenNA.png&quot;), # the following line focuses on the graph plot=grid.draw(gt[ge$t:ge$b, ge$l:ge$r]), # width and height should be experimentally adjusted to remove white space dpi=300,width=8.4,height=4.65) Interpretation: V(iwNetwork)$eigenvector &lt;- eigen_centrality(iwNetwork)$vector eigen_centrality(iwNetwork, directed=FALSE)$vector %&gt;% sort(decreasing=TRUE) %&gt;% .[1:15] ## ITIL_480E462N_S ROUTPOINT1803_499E530N_O ## 1.000000e+00 9.452880e-01 ## ROUTPOINT1802_466E437N_O SUWAR_499E544N_S ## 3.751690e-01 1.826955e-01 ## ROUTPOINT1801_471E433N_O BALANJAR_464E432N_S ## 2.512616e-02 2.365857e-02 ## BULGHAR_492E548N_S SAMANDAR_475E429N_S ## 1.310720e-02 1.661299e-03 ## SUGHDABIL_452E422N_S BABABWAB_483E420N_S ## 3.706776e-04 2.095817e-04 ## SHAKKI_472E413N_S TIFLIS_448E420N_S ## 3.158397e-05 1.635814e-05 ## JISRSAMUR_484E418N_S ROUTPOINT1612_471E405N_O ## 5.990244e-06 3.282977e-06 ## QALAIBNKANDAMAN_451E415N_S ## 1.127935e-06 hist(eigen_centrality(iwNetwork, directed=FALSE)$vector) Let’s map this: eigen &lt;- as_data_frame(iwNetwork, what=&quot;vertices&quot;) %&gt;% slice_max(eigenvector, n = 15) %&gt;% filter(top_type != &quot;xroads&quot;) annotData &lt;- eigen currentMap &lt;- IslamicWorldBase + geom_point(data = nodes, aes(x=lon, y=lat), col=&quot;grey&quot;, alpha=0.5, size=0.25) + geom_point(data = annotData, aes(x=lon, y=lat), col=&quot;red&quot;, size=1) + geom_label_repel(data = annotData, aes(label = names_eng_translit, x=lon, y=lat), max.overlaps = 100) + coord_sf(xlim=c(min(nodes$lon)-1, max(nodes$lon)+1), ylim=c(min(nodes$lat)-1, max(nodes$lat)+1), expand=FALSE) gt &lt;- ggplot_gtable(ggplot_build(currentMap)) ge &lt;- subset(gt$layout, name == &quot;panel&quot;) ggsave(file=paste0(&quot;./files/networks/IW_eigen.png&quot;), # the following line focuses on the graph plot=grid.draw(gt[ge$t:ge$b, ge$l:ge$r]), # width and height should be experimentally adjusted to remove white space dpi=300,width=8.4,height=4.65) Interpretation: 10.4.6.3 Betweenness V(iwNetwork)$betweennessNA &lt;- betweenness(iwNetwork, directed=FALSE, weights=NA) betweenness(iwNetwork, directed=FALSE, weights=NA) %&gt;% sort(decreasing=TRUE) %&gt;% .[1:15] ## KUNDUR_581E351N_S NIBAJ_444E263N_S ASTARABADH_544E367N_S ## 338598.5 304442.1 292848.2 ## DIMASHQ_363E335N_S RAYY_515E356N_S HARA_621E343N_S ## 289819.3 287089.2 286677.6 ## SARIYA_531E365N_S BASRA_477E304N_S MIHRAWAN_536E366N_S ## 284791.6 281895.0 281474.3 ## TAMISHA_540E367N_S NAMIYA_543E367N_S HAFARABUMUSA_459E284N_S ## 280990.2 280528.4 278896.4 ## YUNABIDH_586E342N_S HISNMAHDI_483E305N_S ROUTPOINT0303_481E304N_O ## 278313.7 275781.8 274896.4 hist(betweenness(iwNetwork, directed=FALSE, weights=NA)) Let’s map this: btwNA &lt;- as_data_frame(iwNetwork, what=&quot;vertices&quot;) %&gt;% slice_max(betweennessNA, n = 15) %&gt;% filter(top_type != &quot;xroads&quot;) annotData &lt;- btwNA currentMap &lt;- IslamicWorldBase + geom_point(data = nodes, aes(x=lon, y=lat), col=&quot;grey&quot;, alpha=0.5, size=0.25) + geom_point(data = annotData, aes(x=lon, y=lat), col=&quot;red&quot;, size=1) + geom_label_repel(data = annotData, aes(label = names_eng_translit, x=lon, y=lat), max.overlaps = 100) + coord_sf(xlim=c(min(nodes$lon)-1, max(nodes$lon)+1), ylim=c(min(nodes$lat)-1, max(nodes$lat)+1), expand=FALSE) gt &lt;- ggplot_gtable(ggplot_build(currentMap)) ge &lt;- subset(gt$layout, name == &quot;panel&quot;) ggsave(file=paste0(&quot;./files/networks/IW_btwNA.png&quot;), # the following line focuses on the graph plot=grid.draw(gt[ge$t:ge$b, ge$l:ge$r]), # width and height should be experimentally adjusted to remove white space dpi=300,width=8.4,height=4.65) Interpretation: V(iwNetwork)$betweenness &lt;- betweenness(iwNetwork, directed=FALSE) betweenness(iwNetwork, directed=FALSE) %&gt;% sort(decreasing=TRUE) %&gt;% .[1:15] ## BAGHDAD_443E333N_S SAYLAHIN_440E334N_S ANBAR_437E333N_S ## 493558 373114 372414 ## HIT_428E336N_S RABB_432E334N_S DIMASHQ_363E335N_S ## 372269 371742 355638 ## KUSWA_362E333N_S ROUTPOINT0121_362E333N_O NAYSABUR_587E361N_S ## 324745 324120 307076 ## HULWAN_459E344N_S SUWA_378E337N_S QASRRIH_591E360N_S ## 298450 295024 293207 ## NAHRAWAN_445E334N_S QASRSHIRIN_456E344N_S KHANIQIN_454E343N_S ## 292154 292059 291891 hist(betweenness(iwNetwork, directed=FALSE)) Let’s map this: btw &lt;- as_data_frame(iwNetwork, what=&quot;vertices&quot;) %&gt;% slice_max(betweenness, n = 15) %&gt;% filter(top_type != &quot;xroads&quot;) annotData &lt;- btw currentMap &lt;- IslamicWorldBase + geom_point(data = nodes, aes(x=lon, y=lat), col=&quot;grey&quot;, alpha=0.5, size=0.25) + geom_point(data = annotData, aes(x=lon, y=lat), col=&quot;red&quot;, size=1) + geom_label_repel(data = annotData, aes(label = names_eng_translit, x=lon, y=lat), max.overlaps = 100) + coord_sf(xlim=c(min(nodes$lon)-1, max(nodes$lon)+1), ylim=c(min(nodes$lat)-1, max(nodes$lat)+1), expand=FALSE) gt &lt;- ggplot_gtable(ggplot_build(currentMap)) ge &lt;- subset(gt$layout, name == &quot;panel&quot;) ggsave(file=paste0(&quot;./files/networks/IW_btw.png&quot;), # the following line focuses on the graph plot=grid.draw(gt[ge$t:ge$b, ge$l:ge$r]), # width and height should be experimentally adjusted to remove white space dpi=300,width=8.4,height=4.65) Interpretation: 10.4.7 The Shortest Path You may be interested in finding the shortest path within a specific network. We can do that with the same igraph library and put it on the map. Let’s say, we want to find the shortest path from Baghdad (Baġdād) to Damascus (Dimašq). The following code will give us a vector (sequence) of nodes from one point to another. The second line of code extracts IDs of places from a list of values (we will need a simple vector). baghdad_to_damascus &lt;- shortest_paths(iwNetwork, from = &quot;BAGHDAD_443E333N_S&quot;, to = &quot;DIMASHQ_363E335N_S&quot;, weights = E(iwNetwork)$weight)$vpath baghdad_to_damascus &lt;- names(unlist(baghdad_to_damascus)) The shortest path is found with the Dijkstra algorithm, which is currently the most standard way of calculating the shortest path within a network. Essentially, it finds the path between A and B, where the sum of edges (like distance in meters, for example) is the shortest. Therte are plenty of videos on YouTube with the detailed explanations of how it works (for example, this). Please, take a look, understanding how it works may help you to find a way to use it in other contexts. We can graph this in the following manner (for simplicity, the red line does not follow the actual routes, but draws a straight line between settlements along the path): path &lt;- tibble(ID = baghdad_to_damascus) %&gt;% left_join(nodes, by = c(&quot;ID&quot; = &quot;settlement_id&quot;)) annotData &lt;- path IslamicWorldBase + geom_path(data = annotData, aes(x=lon, y=lat), col=&quot;red&quot;) + geom_point(data = annotData, aes(x=lon, y=lat), col=&quot;red&quot;, size=2) + geom_label_repel(data = annotData, aes(label = names_eng_translit, x=lon, y=lat)) + coord_sf(xlim=c(min(annotData$lon)-5, max(annotData$lon)+5), ylim=c(min(annotData$lat)-3, max(annotData$lat)+3), expand=FALSE) Everything worked as planned, but we need to consider geography and history in order to generate a path that actually makes sense. If we look at the image below, the shortest path (these paths are modeled in althurayya.github.io). The problem with the shortest path is that it is going through the desert, and while it is possible to take this path, this was the path that was avoided as very dangerous. The prefered path was to travel along the Euphrates or the Tigris rivers, and, preferably, along the path with more settlements along the way. On the map below the green path is closer to the prefered option (ideally, it should go through Samarra (Sāmarrāʾ), Mosul (al-Mawṣil), Ar Raqqah (al-Raqqaŧ), and, probably, Aleppo (Ḥalab)). This is where we can modify some parameters of our network in order to make it work more in line with our geographical and historical knowledge. The Dijkstra algorithm takes into account exclusively the lengths of route sections between the nodes in the network, but we can modify these lengths to make the Dijkstra algorithm work the way we want. This will be the easiest and the most flexible way to re-model our network — we can modify these lengths by introducing additional parameters (multipliers, or dividers). For example, if a node is a “capital” or a “town,” it will be preferable to travel through this node, rather than through a “village” or a “waystation.” Say, we have two equally plausible routes, one between a town and a waystation and another between the same town and another town. We can assign specific multipliers to the types of settlements and use them to adjust the length of paths. Say, a multiplier for “town” will be 0.5, and for a “waystation” — 2. This will make the route between two towns “shorter” that the route between a town and a waystation. As a result, the Dijkstra algorithm will be giving preference to these “shorter” paths. Now, how can we implement this? These are the types of nodes that we have. We add multipliers that will help us to reduce or to increase “lengths” of routes based on the types of nodes that they connect. types &lt;- nodes$top_type %&gt;% sort() %&gt;% unique() types &lt;- tibble(type = types, mltp = c(0.33, 0.25, 1, 1, 0.5, 1, 2, 2, 2)) types ## # A tibble: 9 x 2 ## type mltp ## &lt;chr&gt; &lt;dbl&gt; ## 1 capitals 0.33 ## 2 metropoles 0.25 ## 3 quarters 1 ## 4 sites 1 ## 5 towns 0.5 ## 6 villages 1 ## 7 waters 2 ## 8 waystations 2 ## 9 xroads 2 First, let’s add these multipliers to our nodes: nodesM &lt;- nodes %&gt;% left_join(types, by = c(&quot;top_type&quot; = &quot;type&quot;)) nodesM ## # A tibble: 1,692 x 7 ## settlement_id names_eng_transl… region_URI top_type lon lat mltp ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 QAHIRA_312E300N_S al-Qāhiraŧ Misr_RE metropol… 31.2 30.0 0.25 ## 2 WASHQA_003W421N_S Wašqaŧ Andalus_RE towns -0.354 42.2 0.5 ## 3 BALANSIYYA_004W394… Balansiyyaŧ Andalus_RE towns -0.415 39.4 0.5 ## 4 SHAQR_004W391N_S al-Šaqr Andalus_RE villages -0.437 39.2 1 ## 5 QANT_004W383N_S Qānt Andalus_RE towns -0.471 38.3 0.5 ## 6 SHATIBA_005W389N_S Šātibaŧ Andalus_RE towns -0.523 39.0 0.5 ## 7 SARAQUSA_009W416N_S Saraqūsaŧ Andalus_RE towns -0.929 41.6 0.5 ## 8 MURSIYA_011W379N_S Mursiyaŧ Andalus_RE towns -1.11 38.0 0.5 ## 9 TUTILA_016W420N_S Tuṭīlaŧ Andalus_RE towns -1.63 42.0 0.5 ## 10 LURQA_017W376N_S Lurqaŧ Andalus_RE towns -1.73 37.7 0.5 ## # … with 1,682 more rows We also have additional classification of routes in terms of terrain and safety. We can use these as additional multipliers. (These may be more efficient, but they are more time consuming to create.) terrainDF &lt;- tibble(&quot;terrain&quot; = c(&quot;desert&quot;, &quot;normal&quot;, &quot;mountain&quot;, &quot;river&quot;), &quot;mltp&quot; = c(2, 1, 1.25, 0.75)) terrainDF ## # A tibble: 4 x 2 ## terrain mltp ## &lt;chr&gt; &lt;dbl&gt; ## 1 desert 2 ## 2 normal 1 ## 3 mountain 1.25 ## 4 river 0.75 safetyDF &lt;- tibble(&quot;safety&quot; = c(&quot;dangerous&quot;, &quot;safe&quot;, &quot;normal&quot;), &quot;mltp&quot; = c(2, 0.75, 1)) safetyDF ## # A tibble: 3 x 2 ## safety mltp ## &lt;chr&gt; &lt;dbl&gt; ## 1 dangerous 2 ## 2 safe 0.75 ## 3 normal 1 Now, we can generate new “weights” for our edges. Note: there are no strict rules with regard to how you modify your network, your nodes and your edges; it must make sense, so, use your judgement; consult your peers and your advisers; always clearly describe the process of your modifications. For example, the following is happenning below: we multiply the length in meters by the sum of node multipliers (here lower values will turn nodes into magnets of sorts—metropoles and capitals will act as natural attractors); then we multiply the resulting values by the sum of “terrain” and “safety” multipliers (here higher values will make edges “longer”—i.e, routes that go through deserts will become longer than routes ging through a plain). # simply reloading edges data edges &lt;- read_delim(&quot;./data_temp/althurayya/routes.csv&quot;, &quot;\\t&quot;, escape_double = FALSE, trim_ws = TRUE) ## Parsed with column specification: ## cols( ## route_id = col_character(), ## sToponym = col_character(), ## sToponym_type = col_character(), ## eToponym = col_character(), ## eToponym_type = col_character(), ## terrain = col_character(), ## safety = col_character(), ## coordinates = col_character(), ## meter = col_double() ## ) edges &lt;- edges %&gt;% mutate(weight = meter) %&gt;% select(sToponym, eToponym, weight, meter, terrain, safety) head(edges) ## # A tibble: 6 x 6 ## sToponym eToponym weight meter terrain safety ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; ## 1 RIHA_354E318N_S NABULUS_352E322N_S 48742 48742 mountain safe ## 2 ZARQA_360E320N_S AMMAN_359E319N_S 22288 22288 river dangerous ## 3 ZARQA_360E320N_S ADHRIAT_360E326N_S 67802 67802 desert normal ## 4 ADHRIAT_360E326N_S ZARQA_360E320N_S 61334 61334 mountain dangerous ## 5 NAWA_360E328N_S ADHRIAT_360E326N_S 31554 31554 normal safe ## 6 JASIM_360E329N_S AQABAFIQ_356E327N_S 41808 41808 mountain safe Now, updating the weights based on our multipliers: nodesL &lt;- nodesM %&gt;% select(settlement_id, mltp) edgesM &lt;- edges %&gt;% left_join(nodesL, by = c(&quot;sToponym&quot; = &quot;settlement_id&quot;)) %&gt;% left_join(nodesL, by = c(&quot;eToponym&quot; = &quot;settlement_id&quot;)) %&gt;% left_join(terrainDF, by = c(&quot;terrain&quot; = &quot;terrain&quot;)) %&gt;% left_join(safetyDF, by = c(&quot;safety&quot; = &quot;safety&quot;)) %&gt;% mutate(weight_mod = meter) %&gt;% mutate(weight_mod = weight_mod * (mltp.x + mltp.y)) %&gt;% mutate(weight_mod = weight_mod * (mltp.x.x + mltp.y.y)) head(edgesM) ## # A tibble: 6 x 11 ## sToponym eToponym weight meter terrain safety mltp.x mltp.y mltp.x.x mltp.y.y ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 RIHA_35… NABULUS… 48742 48742 mounta… safe 0.5 0.5 1.25 0.75 ## 2 ZARQA_3… AMMAN_3… 22288 22288 river dange… 2 0.5 0.75 2 ## 3 ZARQA_3… ADHRIAT… 67802 67802 desert normal 2 0.33 2 1 ## 4 ADHRIAT… ZARQA_3… 61334 61334 mounta… dange… 0.33 2 1.25 2 ## 5 NAWA_36… ADHRIAT… 31554 31554 normal safe 0.5 0.33 1 0.75 ## 6 JASIM_3… AQABAFI… 41808 41808 mounta… safe 2 1 1.25 0.75 ## # … with 1 more variable: weight_mod &lt;dbl&gt; Now, let’s try to find the shortest route with our new data: iwNetworkMod &lt;- graph_from_data_frame(d=edgesM, vertices=nodesM, directed=FALSE) baghdad_to_damascusMod &lt;- shortest_paths(iwNetworkMod, from = &quot;BAGHDAD_443E333N_S&quot;, to = &quot;DIMASHQ_363E335N_S&quot;, weights = E(iwNetworkMod)$weight_mod)$vpath baghdad_to_damascusMod &lt;- names(unlist(baghdad_to_damascusMod)) pathMod &lt;- tibble(ID = baghdad_to_damascusMod) %&gt;% left_join(nodes, by = c(&quot;ID&quot; = &quot;settlement_id&quot;)) pathModLabels &lt;- pathMod %&gt;% mutate(label = names_eng_translit) %&gt;% filter(top_type == &quot;metropoles&quot; | top_type == &quot;capitals&quot;) annotData &lt;- pathMod IslamicWorldBase + geom_path(data = annotData, aes(x=lon, y=lat), col=&quot;red&quot;) + geom_point(data = annotData, aes(x=lon, y=lat), col=&quot;red&quot;, size=2) + geom_label_repel(data = pathModLabels, aes(label = label, x=lon, y=lat), max.overlaps = 100) + coord_sf(xlim=c(min(annotData$lon)-5, max(annotData$lon)+5), ylim=c(min(annotData$lat)-3, max(annotData$lat)+3), expand=FALSE) As you can see, the results are quite what we wanted. This is is not the easiest approach to implement, but it will give you full control over modeling different processes within your geographical networks. (Important: the data used in this section is not complete; “terrain” and “safety” classifications are random, except for this specific example.) 10.4.8 Clusters and/or Communities A way to find large components of any network is to apply some cluster analysis algorithms. There are many different algorithms which are included in igraph. One needs to understand how they work and for which purposes they have been developed. For our current context, the following algorithms are most fitting. Please, check the … 10.4.9 Sparsifying a Network In some cases your network may be too dense. This will effecively mean that you will not be able to get anything useful from social network analysis methods. What one needs to do in this case is to make the network more sparse. There is a number of ways how one can do this. Ideally, one needs to remodel the network by revising parameters that go into the weights of edges. The simplest way to “sparsify” a network is by deleting edges whose weight is below a certain threshold. In the example below (from Kateto), edges whose value is below mean are deleted from the network. As a result the network should break down into more distinct communities (or, actually, disconnected components). cut.off &lt;- mean(E(iwNetwork)$weight) summary(E(iwNetwork)$weight) ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 1687 23842 38387 55530 62771 861693 cutt.off &lt;- 62771 iwNetwork_sparse &lt;- delete_edges(iwNetwork, E(iwNetwork)[weight &gt; cut.off]) Let’s try to map these disconnected components: cut.off &lt;- 62771 # 1687 23842 38387 55530 62771 861693 fileName &lt;- paste0(&quot;./files/networks/IW_sparse_75f.png&quot;) iwNetwork_sparse &lt;- delete_edges(iwNetwork, E(iwNetwork)[weight &gt;= cut.off]) nodesLight &lt;- nodes %&gt;% select(settlement_id, lon, lat, top_type) edges_sparce &lt;- as_data_frame(iwNetwork_sparse, what=&quot;edges&quot;) %&gt;% select(from, to) %&gt;% left_join(nodesLight, by = c(&quot;from&quot; = &quot;settlement_id&quot;)) %&gt;% left_join(nodesLight, by = c(&quot;to&quot; = &quot;settlement_id&quot;)) %&gt;% filter(top_type.x != &quot;waystations&quot; &amp; top_type.x != &quot;xroads&quot;) %&gt;% filter(top_type.y != &quot;waystations&quot; &amp; top_type.y != &quot;xroads&quot;) currentMap &lt;- IslamicWorldBase + geom_segment(data = edges_sparce, aes(x=lon.x, y=lat.x, xend=lon.y, yend=lat.y), col=&quot;red&quot;, size=0.5) + coord_sf(xlim=c(min(nodes$lon)-1, max(nodes$lon)+1), ylim=c(min(nodes$lat)-1, max(nodes$lat)+1), expand=FALSE) gt &lt;- ggplot_gtable(ggplot_build(currentMap)) ge &lt;- subset(gt$layout, name == &quot;panel&quot;) ggsave(file=fileName, # the following line focuses on the graph plot=grid.draw(gt[ge$t:ge$b, ge$l:ge$r]), # width and height should be experimentally adjusted to remove white space dpi=300,width=8.4,height=4.65) 10.4.10 Other networks on maps … 10.5 Additional Materials on Networks in R Katherine Ognyanova (2017-2018). Static and dynamic network visualization with R. https://kateto.net/network-visualization. Chapter 6 in: Arnold, Taylor, and Lauren Tilton. 2015. Humanities Data in R. New York, NY: Springer Science+Business Media. See also: Chapter 1 in Yunran Chen. Introduction to Network Analysis Using R (https://yunranchen.github.io/intro-net-r/index.html) Jesse Sadler. 2017. Introduction to Network Analysis with R: Creating static and interactive network graphs, https://www.jessesadler.com/post/network-analysis-with-r/. On communities: http://networksciencebook.com/chapter/9. https://www.r-bloggers.com/summary-of-community-detection-algorithms-in-igraph-0-6/ https://stackoverflow.com/questions/9471906/what-are-the-differences-between-community-detection-algorithms-in-igraph/ 10.6 Homework Submit your knitted notebook. 10.7 Submitting homework Homework assignment must be submitted by the beginning of the next class; Email your homework to the instructor as attachments. In the subject of your email, please, add the following: 070184-LXX-HW-YourLastName-YourMatriculationNumber, where LXX is the numnber of the lesson for which you submit homework; YourLastName is your last name; and YourMatriculationNumber is your matriculation number. "],
["l11-gis-v.html", "11 L11: GIS V 11.1 Interactive Maps with R 11.2 Homework 11.3 Submitting homework", " 11 L11: GIS V 11.1 Interactive Maps with R Coming soon 11.1.1 Goals … 11.1.2 Software R 11.1.3 Additional Materials … … 11.2 Homework … Submit your knitted notebook. 11.3 Submitting homework Homework assignment must be submitted by the beginning of the next class; Email your homework to the instructor as attachments. In the subject of your email, please, add the following: 070184-LXX-HW-YourLastName-YourMatriculationNumber, where LXX is the numnber of the lesson for which you submit homework; YourLastName is your last name; and YourMatriculationNumber is your matriculation number. "],
["l12-pojects-i.html", "12 L12: Pojects I 12.1 Preparing Data 12.2 Homework 12.3 Submitting homework", " 12 L12: Pojects I 12.1 Preparing Data Coming soon 12.1.1 Goals … 12.1.2 Software R 12.1.3 Additional Materials … 12.2 Homework … Submit your knitted notebook. 12.3 Submitting homework Homework assignment must be submitted by the beginning of the next class; Email your homework to the instructor as attachments. In the subject of your email, please, add the following: 070184-LXX-HW-YourLastName-YourMatriculationNumber, where LXX is the numnber of the lesson for which you submit homework; YourLastName is your last name; and YourMatriculationNumber is your matriculation number. "],
["l13-pojects-ii.html", "13 L13: Pojects II 13.1 Choosing Suitable Methods 13.2 Homework 13.3 Submitting homework", " 13 L13: Pojects II 13.1 Choosing Suitable Methods Coming soon 13.1.1 Goals … 13.1.2 Software R 13.1.3 Additional Materials … 13.2 Homework … Submit your knitted notebook. 13.3 Submitting homework Homework assignment must be submitted by the beginning of the next class; Email your homework to the instructor as attachments. In the subject of your email, please, add the following: 070184-LXX-HW-YourLastName-YourMatriculationNumber, where LXX is the numnber of the lesson for which you submit homework; YourLastName is your last name; and YourMatriculationNumber is your matriculation number. "],
["l14-pojects-iii.html", "14 L14: Pojects III 14.1 Interpreting Results 14.2 Homework 14.3 Submitting homework", " 14 L14: Pojects III 14.1 Interpreting Results Coming soon 14.1.1 Goals … 14.1.2 Software R 14.1.3 Additional Materials … 14.2 Homework … Submit your knitted notebook. 14.3 Submitting homework Homework assignment must be submitted by the beginning of the next class; Email your homework to the instructor as attachments. In the subject of your email, please, add the following: 070184-LXX-HW-YourLastName-YourMatriculationNumber, where LXX is the numnber of the lesson for which you submit homework; YourLastName is your last name; and YourMatriculationNumber is your matriculation number. "],
["l15-final-presentations.html", "15 L15: Final Presentations 15.1 Presenting Your Work 15.2 Homework 15.3 Submitting homework", " 15 L15: Final Presentations 15.1 Presenting Your Work Coming soon 15.1.1 Goals … 15.1.2 Software R 15.1.3 Additional Materials … 15.2 Homework … Submit your knitted notebook. 15.3 Submitting homework Homework assignment must be submitted by the beginning of the next class; Email your homework to the instructor as attachments. In the subject of your email, please, add the following: 070184-LXX-HW-YourLastName-YourMatriculationNumber, where LXX is the numnber of the lesson for which you submit homework; YourLastName is your last name; and YourMatriculationNumber is your matriculation number. "],
["misc-i-reading-assignments.html", "MISC I: Reading Assignments How to complete the Reading-Reporting Assignments Preparing and Submitting Your Reports Suggested Monographs", " MISC I: Reading Assignments How to complete the Reading-Reporting Assignments Reading-Reporting Assignments: one of your tasks will be to identify relevant readings (articles, book sections), read them, and provide short summaries (250-500 words) in the shared Zotero library for our course. You need to submit 5 such short summaries for full credit. “Relevant” means that these readings must be relevant to your own research interests. Ideally, you will use these readings as an additional background for your final projects. Some readings will be suggested, but I would encourage you to invest some time into this task and find your own readings (which is now very easy with such available resources as JSTOR). Preparing and Submitting Your Reports You will need Zotero for this task: Download and install Zotero from https://www.zotero.org/; Make sure to create an account and login into your accout both online and in Zotero; Send me your user name so that I could add you to our group library in Zotero; Make sure to install a browser connector into the browser of your choice (Chrome and Firefox are the best choices); You can use this link: https://www.zotero.org/download/connectors Alternatively, in Zotero, go toTools &gt; Install browser connector The browser connector will allow you to add publications automatically into Zotero from websites that you visit. This is very convenient to collect bibliography (and often automatically download PDFs, if they are available). In order to download bibliographical data and PDFs into your Zotero from JSTOR (and some other similar kind of libraries), you need to know a couple of things: you need to be logged in via your university account; otherwise you will not have access to PDFs; you need to download the first PDF by manually clicking download button: it is ask you to agree to terms and conditions; after that you can use the browser connector button. in Zotero: collect publications on GIS that are relevant to your interests; please, do spend some time looking for publications that are relevant to your interests. Do not grab the first things that you find. Use this as an opportunity to learn something new and interesting. The publications do not have to be from your field, whichever it is, but rather on a method or a case study that is likely to be applicable to your research area. skim through what you have collected: check the structure; read intros and conclusions; skim through the rest; based on this pre-reading, pick the most interesting 5 pieces; read them carefully and write your summaries, which must include the following: briefly: what is the article about? what GIS methods and technologies have been used in the study? Any specific software that should be mentioned? what are the findings? specifically, what did GIS allow to discover versus other non-GIS methods? what are the most interesting (i.e., most relevant to your interests) aspects of the study? the volume should be 250-500 words NB: you can write these summaries in any editor. When you are ready to submit them, you should do so by adding a Note to a specific publication and copy/paste your summary into that note. Sharing your summaries: in the rgis2021 group library in Zotero, create your own subcollection, which must be named Firstname Lastname - YOUMATRICNUMBER; paste your records — with notes containing your summaries — into your folder; let me know that you are done :) Suggested Monographs Check the References page for a list of suggested monographs; those also can be found in our group library rgis2021 available through Zotero. "],
["syllabus.html", "Syllabus Course Details Course Evaluation Class Participation Homework Assignments Final Project Practice worksheets (R Notebooks) Study materials Software, Tools, &amp; Technologies Schedule Lesson Topics Additional", " Syllabus Course: 070184 UE Methodological course - Digital Humanities Skills: Intro to GIS (2021S), R Edition u:find Link: https://ufind.univie.ac.at/en/course.html?lv=070184&amp;semester=2021S Meeting time: Tu 11:30-13:00 Meeting place: due to COVID, all meetings will be held online Instructor: Dr. Maxim Romanov, maxim.romanov@univie.ac.at Language of instruction: English Office hours: Tu 13:30-15:00 (on Zoom; please, contact beforehand!) Office: Department of History, Maria-Theresien-Straße 9, 1090 Wien, Room 1.10 Course Details u:find Link: https://ufind.univie.ac.at/en/course.html?lv=070184&amp;semester=2021S Meeting time: Tu 11:30-13:00 Meeting place: due to COVID, all meetings will be held online Aims, contents and method of the course GIS, which stands for geographical information system(s), has become an important tool of a historian — to the point that scholars in many humanities disciplines talk about “spatial turns.” Indeed, GIS allows us as historians to pay much closer attention to the spatial dimension in studying the past. To begin with, creating maps became so much easier now. Yet, more importantly, we can now map our data to understand spatial distribution of different phenomena — and how this distribution changed over time; we can map data representing different phenomena and study how they may have affected each other; we can map connections and study how physical space affects the formation of networks; and so much more. This course will focus on the use of the programming language R which shines when it comes to data analysis and creating robust visualizations. The course will consist of three main parts. Part I will introduce you to the basics of R and its philosophy of “tidy data.” Part II will focus on specific methods and techniques of spatial analysis. Part III will require you to focus on your own research projects. The language of the course is English. Assessment and permitted materials Assessment will be based on class participation, homework assignments, and a final project (final projects can be prepared either individually or in groups; ideally, your final project should be directly connected to research projects that you carry out for other courses or for your BA, MA, or PhD theses). Minimum requirements and assessment criteria No prior programming experience is required, but familiarity with the command line and basic principles of programming will be beneficial. Course Evaluation Course evaluation will be a combination of in-class participation (30%), weekly homework assignments (50%), and the final project (20%). Class Participation Attendance is required; regular participation is the key to completing the course; all students must come with their laptops; homework assignments must be submitted on time (some can be completed later as a part of the final project, but this must be discussed with the instructor whenever the issue arises); the final project must be submitted on time. Homework Assignments Homework assignments are due before the beginning of the following class; You will need to complete your worksheet and generate HTML or PDF document with the results, which you then submit to the instructor as attachments via email; In the subject of your email, please, use the following format: CourseID-LessonID-HW-Lastname-matriculationNumber, for example, if I were to submit homework for the first lesson, my subject header would look like: 070184-L01-HW-Romanov-12435687. DH is a collaborative field, so you are most welcome to work on your homework assignments in groups, however: you must still submit it. That is, if a groups of three works on one assignment, there must be three separate submissions emailed from each member’s email. Reading-Reporting Assignments: one of your tasks will be to identify relevant readings (articles, book sections), read them, and provide short summaries (250-500 words) in the shared Zotero library for our course. You need to submit 5 such short summaries for full credit. “Relevant” means that these readings must be relevant to your own research interests. Ideally, you will use these readings as an additional background for your final projects. Some readings will be suggested, but I would encourage you to invest some time into this task and find your own readings (which is now very easy with such available resources as JSTOR). NB: For most classes you will need to complete and submite worksheets. Some questions in those worksheets will be easy, but some you might find to be difficult and even impossible. We will go over the difficult parts of each worksheet in class, so do not worry. The main goal is to practice, since for most students this course will be very new and very strange. In practical terms this means that you need to to submit your worksheet in time with your best try for each question. The worksheets will be graded by completion, i.e. you will get full credit if you: 1) complete all the easy and moderately difficult questions; 2) give an honest try to the very difficult questions; 3) ask for help in class and/or office hours to make sure that you understand the challenges. Final Project The final project is your own research project that uses collections of texts of your interest and research methods introduced inthe course. You are encouraged to explore methods outside of those covered within the course. Ideally, your research project should be directly related to your main research project that you undertake in your studies. You are welcome to work in groups on your final projects, but make sure to discuss that with the instructor first. Practice worksheets (R Notebooks) 01_worksheets_familiar-with-r.Rmd.zip 02_worksheets_data-structures.Rmd.zip 03_worksheets_data-manipulation-introduction.Rmd.zip 04_worksheets_data-manipulation-continued.Rmd.zip 05_worksheets_ggplot2-introduction-MGR-mod.Rmd.zip 06_worksheets_functions.Rmd.zip NB: Worksheets 1-6 have beed developed by Lincoln Mullen. Source: Lincoln A. Mullen, Computational Historical Thinking: With Applications in R (2018–): http://dh-r.lincolnmullen.com. Study materials Necessary materials will be provided. The following list includes valuable resources on R: Arnold, Taylor, and Lauren Tilton. Humanities Data in R. New York, NY: Springer Science+Business Media, 2015. Healy, Kieran Data Visualization: A Practical Guide. Princeton University Press, 2018. ISBN: 978-0691181622. http://socviz.co/. Hadley Wickham &amp; Garrett Grolemund, R for Data Science: Import, Tidy, Transform, Visualize, and Model Data. O’Reilly, 2017. ISBN: 978-1491910399. https://r4ds.had.co.nz/. Wickham, Hadley. Advanced R, Second Edition. 2 edition. Boca Raton: Chapman and Hall/CRC, 2019. http://adv-r.had.co.nz/. Also check https://bookdown.org/ for more books on R. Software, Tools, &amp; Technologies The main tools for the course will be the programming language R and RStudio, the premier integrated development environment for R. R: https://cloud.r-project.org/ (choose the version for your operating system!) RStudio: https://rstudio.com/products/rstudio/download/ (RStudio Desktop, Open Source License — the free version) We will also use a variety of packages: swirl https://swirlstats.com/ knitr https://yihui.name/knitr/ R markdown https://rmarkdown.rstudio.com/, https://bookdown.org/yihui/rmarkdown/ Additionally, bookdown https://bookdown.org/, https://bookdown.org/yihui/bookdown/ tidyverse https://www.tidyverse.org/ ggplot2 https://ggplot2.tidyverse.org/ Tutorial: http://r-statistics.co/ggplot2-Tutorial-With-R.html Useful cookbook: http://r-statistics.co/Top50-Ggplot2-Visualizations-MasterList-R-Code.html ggvis https://ggvis.rstudio.com/, https://ggvis.rstudio.com/ggvis-basics.html shiny https://shiny.rstudio.com/ Schedule Location: Hörsaal 30 Hauptgebäude, 1.Stock, Stiege 7; due to COVID, all meetings will be held online via video-conferencing Tuesday 02.03. 11:30 - 13:00 Tuesday 09.03. 11:30 - 13:00 Tuesday 16.03. 11:30 - 13:00 Tuesday 23.03. 11:30 - 13:00 2-WEEK BREAK 2-WEEK BREAK Tuesday 13.04. 11:30 - 13:00 Tuesday 20.04. 11:30 - 13:00 Tuesday 27.04. 11:30 - 13:00 Tuesday 04.05. 11:30 - 13:00 Tuesday 11.05. 11:30 - 13:00 Tuesday 18.05. 11:30 - 13:00 Tuesday 01.06. 11:30 - 13:00 Tuesday 08.06. 11:30 - 13:00 Tuesday 15.06. 11:30 - 13:00 Tuesday 22.06. 11:30 - 13:00 Tuesday 29.06. 11:30 - 13:00 Lesson Topics [ #01 ] General Introduction: Making Sure Everything Works; Getting to know R [ #02 ] Basics I: Data Structures and Subsetting [ #03 ] Basics II: Data Manipulation &amp; Exploratory Analysis [ #04 ] Basics III: Data Visualization; Functions [ ### ] 2-WEEK BREAK: swirl tutorials @ home [ ### ] 2-WEEK BREAK: swirl tutorials @ home [ #05 ] Data I: Collecting, Organizing, Creating [ #06 ] Data II: Modeling &amp; Manipulating === GIS METHODS === [ #07 ] GIS Methods I: Georeferencing (with QGIS) and Geocoding (with R) [ #08 ] GIS Methods II: Creating Base maps: Points, Vectors, Polygons [ #09 ] GIS Methods III: Mapping Categorical Data [ #10 ] GIS Methods IV: Mapping Networks [ #11 ] GIS Methods V: GIS without Maps === DEVELOPING FINAL PROJECTS === [ #12 ] Projects I [ #13 ] Projects II [ #14 ] Projects III [ #15 ] Final Presentations Note: one of the classes might be canceled; this will be announced separately. Lesson materials will be appearing on the website shortly before each class. Lessons will be accessible via the Lessons link on the left panel. Additional Datasets Library of Congress: [DATA] 25 mln book records: http://www.loc.gov/cds/products/MDSConnect-books_all.html Miriam Posner (UCLA): [DATA] collection of datasets: http://miriamposner.com/classes/dh201w19/final-project/datasets/ class materials: http://miriamposner.com/classes/dh201w19/ Lincoln Mullen (George Mason U): [DATA] historydata R-package: https://lincolnmullen.com/software/historydata/ Computational Historical Thinking, https://dh-r.lincolnmullen.com/ "],
["references.html", "References", " References Baker, Alan R. H. 2003. Geography and History: Bridging the Divide. Cambridge Studies in Historical Geography 36. Cambridge, U.K. ; New York: Cambridge University Press. Bodenhamer, David J., John Corrigan, and Trevor M. Harris, eds. 2010. The Spatial Humanities: GIS and the Future of Humanities Scholarship. Spatial Humanities. Bloomington: Indiana University Press. ———, eds. 2015. Deep Maps and Spatial Narratives. The Spatial Humanities. Bloomington: Indiana University Press. Gregory, Ian N. 2013. Troubled Geographies: A Spatial History of Religion and Society in Ireland. The Spatial Humanities. Bloomington ; Indianapolis: Indiana University Press. Gregory, Ian N., and A. Geddes, eds. 2014. Toward Spatial Humanities: Historical GIS and Spatial History. The Spatial Humanities. Bloomington: Indiana University Press. Gregory, Ian, Donald A. DeBats, and Donald Lafreniere, eds. 2018. The Routledge Companion to Spatial History. London ; New York: Routledge Taylor &amp; Francis Group. Gregory, Ian, and Paul S. Ell. 2007. Historical GIS: Technologies, Methodologies, and Scholarship. Cambridge Studies in Historical Geography 39. Cambridge ; New York: Cambridge University Press. Knowles, Anne Kelly, ed. 2014. Geographies of the Holocaust. The Spatial Humanities. Bloomington: Indiana University Press. Lünen, Alexander von. 2013. History and GIS: Epistemologies, Considerations and Reflections. Dordrecht [u.a.]: Springer. Terpstra, Nicholas, and Colin Rose, eds. 2016. Mapping Space, Sense, and Movement in Florence: Historical GIS and the Early Modern City. Routledge Research in Digital Humanities. London ; New York: Routledge,Taylor &amp; Francis Group. Ye, Xinyue, and Hui Lin. 2020. Spatial Synthesis: Computational Social Science and Humanities. https://doi.org/10.1007/978-3-030-52734-1. "]
]
